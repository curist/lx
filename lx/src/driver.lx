// Driver - Orchestrates compilation pipeline (passes):
//   parse → lower → anf → resolve → anf-inline → lower-intrinsics → (codegen)
//
// Responsibilities:
// - Coordinate pass execution
// - Manage import cache for multi-file compilation
// - Handle circular import detection
// - Provide compilation artifacts for query service and codegen
// - ANF runs after lower (optional, default on)
// - Loop lowering runs post-ANF, pre-resolve (always on with ANF, materializes loop limits)
// - ANF inline runs post-resolve (optional, default on)

let parse = import "src/passes/parse/parser.lx"
let lower = import "src/passes/transform/lower.lx"
let anf = import "src/passes/transform/anf.lx"
let anfInline = import "src/passes/transform/anf-inline.lx"
let lowerIntrinsics = import "src/passes/transform/lower-intrinsics.lx"
let resolve = import "src/passes/analysis/resolve.lx"
let typecheck = import "src/passes/analysis/typecheck.lx"
let dce = import "src/passes/analysis/dce.lx"
let peephole = (import "src/passes/opt/peephole-bytecode.lx").peephole
let pipeline = import "src/passes/pipeline.lx"
let fastcheck = import "src/passes/analysis/fastcheck.lx"
let codegen = import "src/passes/emit/codegen.lx"
let verify = import "src/passes/verify/verify-bytecode.lx"
let .{ NODE } = import "src/types.lx"

// ========================================
// Canonical Artifact IDs
// ========================================
// These IDs define the compiler's formal build targets and compilation artifacts.
// Artifact-driven compilation: passes exist to produce artifacts; artifacts define
// scheduling, validity, and correctness.

let ARTIFACT = .{
  // Per-module AST artifacts
  AST_FINAL: "ast.final",                          // Authoritative AST after all transforms

  // Per-module analysis artifacts
  ANALYSIS_RESOLVE: "analysis.resolve",            // Name resolution and scope info
  ANALYSIS_DCE_LOCAL: "analysis.dce.local",        // Local dead code analysis
  ANALYSIS_FASTCHECK: "analysis.fastcheck",        // Fast type representation analysis
  ANALYSIS_TYPECHECK: "analysis.typecheck",        // Optional type inference
  ANALYSIS_DCE_FINAL: "analysis.dce.final",        // DCE after whole-program analysis

  // Per-module bytecode artifacts
  BYTECODE_FUNCTION: "bytecode.function",          // Generated bytecode function
  BYTECODE_VERIFIED: "bytecode.verified",          // Verified bytecode

  // Program-level artifacts
  PROGRAM_MODULE_GRAPH: "program.module_graph",    // Complete module dependency graph
  ANALYSIS_DCE_WHOLE_PROGRAM: "analysis.dce.whole_program",  // Whole-program DCE facts
}

// ========================================
// Stamp Functions (Cache Invalidation)
// ========================================

fn computeAstStamp(opts, sourceHash) {
  // Compute a stamp (fingerprint) for AST configuration.
  // Artifacts are valid only if their astStamp matches the current configuration.
  //
  // Stamp includes:
  // - AST transform configuration (withLower, withAnf, withAnfInline, withLowerIntrinsics)
  // - Source content hash (to invalidate on file edits)
  //
  // For now, we use a simple string concatenation. In the future, this could
  // use a proper hash function.

  let parts = []
  push(parts, opts.withLower and "L" or "_")
  push(parts, opts.withAnf and "A" or "_")
  push(parts, opts.withAnfInline and "I" or "_")
  push(parts, opts.withLowerIntrinsics and "i" or "_")
  push(parts, opts.withTypecheck and "T" or "_")
  push(parts, opts.withDce and "D" or "_")

  // Include source hash to invalidate when file changes
  if sourceHash {
    push(parts, "|src:")
    push(parts, sourceHash)
  }

  join(parts, "")
}

fn computeProgramStamp(modulePaths) {
  // Compute a stamp for program-level state.
  // Whole-program artifacts are valid only if the module graph hasn't changed.
  //
  // Stamp includes:
  // - Set of compiled modules (their paths)
  //
  // NOTE: We concatenate in discovery order. This means the stamp changes if
  // import discovery order changes, even if the module set is identical.
  // A more robust implementation would sort paths or use a set hash.

  if !modulePaths or len(modulePaths) == 0 { return "" }

  let stamp = ""
  for path in modulePaths {
    stamp = stamp + path + ";"
  }
  stamp
}

fn simpleStringHash(source) {
  // Compute CRC32 hash for cache invalidation.
  // Uses zlib's CRC32 implementation for fast, reliable content fingerprinting.
  if !source { return "0" }

  let crc = Lx.zlib.crc32(source)
  str(crc)
}

// ========================================
// Helper Functions
// ========================================

fn remapEnumInfo(prevEnumInfo, resultOrigin) {
  // Remap enum info through origin tracking when node IDs change
  // prevEnumInfo: .{ oldNodeId: enumInfo }
  // resultOrigin: .{ newNodeId: oldNodeId }
  // Returns: .{ newNodeId: enumInfo }

  if !prevEnumInfo or !resultOrigin { return .{} }

  let remapped = .{}
  for newId in keys(resultOrigin) {
    let oldId = resultOrigin[newId]
    if type(oldId) == "number" or type(oldId) == "string" {
      let info = prevEnumInfo[oldId]
      if info { remapped[newId] = info }
    }
  }
  remapped
}

fn getFinalAst(passes) {
  // Get the authoritative AST after all transforms.
  // This is the single source of truth for "what AST should be used?"
  // Previously this logic was duplicated in common.lx and driver.lx.
  //
  // Selection priority:
  // 1. lower-intrinsics (if enabled - post-resolve intrinsic lowering)
  // 2. anf-inline (if enabled - post-resolve ANF optimization)
  // 3. anf (if enabled - ANF transform)
  // 4. lower (if enabled - desugaring)
  // 5. parse (fallback - original AST)

  if !passes { return nil }

  let ast = (passes["lower-intrinsics"] and passes["lower-intrinsics"].ast) or
            (passes["anf-inline"] and passes["anf-inline"].ast) or
            (passes.anf and passes.anf.ast) or
            (passes.lower and passes.lower.ast) or
            (passes.parse and passes.parse.ast)
  ast
}

fn getFinalEnumInfo(passes) {
  // Get the enum info corresponding to the final AST.
  // Enum info is remapped through AST transforms via origin tracking.

  if !passes { return .{} }

  let enumInfo = (passes.anf and passes.anf.enumInfo) or
                 (passes.lower and passes.lower.enumInfo) or
                 (passes.parse and passes.parse.enumInfo) or
                 .{}
  enumInfo
}

// ========================================
// Profile Definitions
// ========================================

fn getProfile(name) {
  // Returns .{ withLower, withAnf, withAnfInline, withLowerIntrinsics, withTypecheck } for the given profile
  // Profiles define curated pass combinations for specific use cases

  if name == "default" {
    // Current compiler semantics: all passes enabled
    // parse → lower → anf → resolve → anf-inline → lower-intrinsics
    return .{
      withLower: true,
      withAnf: true,
      withAnfInline: true,
      withLowerIntrinsics: true,
      withTypecheck: false,
    }
  }

  if name == "typecheck" {
    // Same as default: parse → lower → anf → resolve → anf-inline → lower-intrinsics → typecheck (non-fatal)
    return .{
      withLower: true,
      withAnf: true,
      withAnfInline: true,
      withLowerIntrinsics: true,
      withTypecheck: true,
    }
  }


  if name == "query" {
    // Fast, tooling-oriented pipeline for IDE queries that don't require type inference:
    // parse → lower → resolve
    // (Query service prefers non-ANF AST so imports/structure stay intact.)
    return .{
      withLower: true,
      withAnf: false,
      withAnfInline: false,
      withLowerIntrinsics: false,
      withTypecheck: false,
    }
  }

  // Unknown profile - return nil to signal error
  nil
}

fn getDefaultTarget(profileName) {
  if profileName == "query" { return ARTIFACT.ANALYSIS_RESOLVE }
  if profileName == "typecheck" { return ARTIFACT.ANALYSIS_TYPECHECK }
  ARTIFACT.AST_FINAL
}

// ========================================
// Build Pass Plan
// ========================================

let PASS_ORDER = ["parse", "lower", "anf", "resolve", "dce", "anf-inline", "lower-intrinsics"]

fn passEnabled(passName, needs) {
  if passName == "parse" { return true }
  if passName == "lower" { return needs.withLower == true }
  if passName == "anf" { return needs.withAnf == true }
  if passName == "resolve" { return true }
  if passName == "dce" { return needs.withDce == true }
  if passName == "anf-inline" { return needs.withAnfInline == true }
  if passName == "lower-intrinsics" { return needs.withLowerIntrinsics == true }
  false
}

// ========================================
// Pass Definitions
// ========================================

let PASS_DEFS = .{
  parse: .{
    name: "parse",
    mutatesAst: false,
    provides: ["ast", "parseTree"],
    run: fn(ctx, state) {
      parse(state.source, state.path)
    },
  },
  lower: .{
    name: "lower",
    mutatesAst: false,
    requires: ["ast"],
    provides: ["loweredAst"],
    // enabled: auto-checked via ctx.opts.withLower by pipeline
    run: fn(ctx, state) {
      let result = lower(state.ast, .{ startNodeId: state.nextNodeId })

      // Remap parse enum info (if present) onto lowered node IDs via origin.
      let parseResult = state.passes and state.passes.parse
      if parseResult and parseResult.enumInfo and result and result.origin {
        let remapped = remapEnumInfo(parseResult.enumInfo, result.origin)
        return .{
          success: result.success,
          ast: result.ast,
          origin: result.origin,
          errors: result.errors,
          nextNodeId: result.nextNodeId,
          enumInfo: remapped,
        }
      }

      result
    },
  },
  anf: .{
    name: "anf",
    mutatesAst: false,
    requires: ["loweredAst"],
    provides: ["anfAst", "loweredAst"],  // ANF is a refinement, still satisfies loweredAst contracts
    // enabled: auto-checked via ctx.opts.withAnf by pipeline
    run: fn(ctx, state) {
      let result = anf(state.ast, .{ startNodeId: state.nextNodeId })

      // Remap enum info through ANF transform (node IDs change again).
      let prev = state.passes and state.passes.lower
      if prev and prev.enumInfo and result and result.origin {
        let remapped = remapEnumInfo(prev.enumInfo, result.origin)
        return .{
          success: result.success,
          ast: result.ast,
          origin: result.origin,
          errors: result.errors,
          nextNodeId: result.nextNodeId,
          enumInfo: remapped,
        }
      }

      result
    },
  },
  resolve: .{
    name: "resolve",
    mutatesAst: false,  // Phase 2: import metadata moved to side tables
    requires: ["ast"],  // Works on parse, lowered, or ANF AST
    provides: ["resolution", "scopeInfo"],
    run: fn(ctx, state) {
      let opts = .{
        importCache: ctx.importCache,
        compileModule: ctx.compileModule,
      }
      resolve(state.ast, opts)
    },
  },
  dce: .{
    name: "dce",
    mutatesAst: false,  // Produces side tables only
    requires: ["resolution"],
    provides: ["dce"],
    enabled: fn(ctx, state) {
      ctx.opts.withDce != false
    },
    run: fn(ctx, state) {
      let resolveResult = state.passes.resolve
      dce(state.ast, resolveResult)
    },
  },
  ["anf-inline"]: .{
    name: "anf-inline",
    mutatesAst: true,  // Explicitly mutates AST in-place
    requires: ["anfAst", "resolution"],  // Pipeline auto-checks these requirements
    provides: ["optimizedAst"],
    // enabled: auto-checked via ctx.opts.withAnfInline by pipeline
    run: fn(ctx, state) {
      let resolveResult = state.passes.resolve
      anfInline(state.ast, resolveResult)
    },
  },
  ["lower-intrinsics"]: .{
    name: "lower-intrinsics",
    mutatesAst: true,  // Mutates AST in-place (preserves node IDs)
    requires: ["anfAst", "resolution"],
    provides: ["intrinsicsLoweredAst"],
    // enabled: auto-checked via ctx.opts.withLowerIntrinsics by pipeline
    run: fn(ctx, state) {
      let resolveResult = state.passes.resolve
      lowerIntrinsics(state.ast, resolveResult, nil)
    },
  },
}

let ARTIFACT_SPEC = .{
  ["source"]: .{
    requires: [],
    produces: [],
  },
  ["ast.pre_resolve"]: .{
    requires: ["source"],
    produces: fn(needs) {
      let out = ["parse"]
      if needs.withLower == true { push(out, "lower") }
      if needs.withAnf == true { push(out, "anf") }
      out
    },
  },
  [ARTIFACT.ANALYSIS_RESOLVE]: .{
    requires: ["ast.pre_resolve"],
    produces: ["resolve"],
  },
  [ARTIFACT.ANALYSIS_DCE_LOCAL]: .{
    requires: [ARTIFACT.ANALYSIS_RESOLVE],
    produces: fn(needs) { needs.withDce == true and ["dce"] or [] },
  },
  [ARTIFACT.AST_FINAL]: .{
    requires: ["ast.pre_resolve", ARTIFACT.ANALYSIS_RESOLVE],
    produces: fn(needs) {
      let out = []
      if needs.withAnfInline == true { push(out, "anf-inline") }
      if needs.withLowerIntrinsics == true { push(out, "lower-intrinsics") }
      out
    },
  },
  [ARTIFACT.ANALYSIS_DCE_WHOLE_PROGRAM]: .{
    requires: fn(needs) {
      let reqs = [ARTIFACT.PROGRAM_MODULE_GRAPH]
      if needs.withDce == true { push(reqs, ARTIFACT.ANALYSIS_DCE_LOCAL) }
      reqs
    },
    produces: [],
  },
  [ARTIFACT.ANALYSIS_DCE_FINAL]: .{
    requires: fn(needs) {
      let reqs = [ARTIFACT.ANALYSIS_DCE_LOCAL, ARTIFACT.AST_FINAL]
      if needs.withDce == true { push(reqs, ARTIFACT.ANALYSIS_DCE_WHOLE_PROGRAM) }
      reqs
    },
    produces: [],
  },
  [ARTIFACT.ANALYSIS_FASTCHECK]: .{
    requires: [ARTIFACT.AST_FINAL, ARTIFACT.ANALYSIS_RESOLVE],
    produces: [],
  },
  [ARTIFACT.ANALYSIS_TYPECHECK]: .{
    requires: [ARTIFACT.AST_FINAL, ARTIFACT.ANALYSIS_RESOLVE],
    produces: [],
  },
  [ARTIFACT.BYTECODE_FUNCTION]: .{
    requires: [
      ARTIFACT.AST_FINAL,
      ARTIFACT.ANALYSIS_RESOLVE,
      ARTIFACT.ANALYSIS_FASTCHECK,
      ARTIFACT.ANALYSIS_DCE_FINAL,
    ],
    produces: [],
  },
  [ARTIFACT.BYTECODE_VERIFIED]: .{
    requires: [ARTIFACT.BYTECODE_FUNCTION],
    produces: [],
  },
  [ARTIFACT.PROGRAM_MODULE_GRAPH]: .{
    requires: ["source"],
    produces: [],
  },
}

fn artifactRequires(artifactId, needs) {
  let spec = ARTIFACT_SPEC[artifactId]
  if !spec { return [] }
  let reqs = spec.requires or []
  let evaluated = type(reqs) == "fn" and reqs(needs) or reqs
  type(evaluated) == "array" and evaluated or []
}

fn artifactProduces(artifactId, needs) {
  let spec = ARTIFACT_SPEC[artifactId]
  if !spec { return [] }
  let produces = spec.produces or []
  let evaluated = type(produces) == "fn" and produces(needs) or produces
  type(evaluated) == "array" and evaluated or []
}

fn validateArtifactSpec(needs) {
  let errors = []
  let artifactIds = keys(ARTIFACT_SPEC)
  let artifactSet = .{}
  for id in artifactIds { artifactSet[id] = true }

  for id in artifactIds {
    let spec = ARTIFACT_SPEC[id]
    let rawReqs = spec and spec.requires or []
    let evaluatedReqs = type(rawReqs) == "fn" and rawReqs(needs) or rawReqs
    if type(evaluatedReqs) != "array" {
      push(errors, "Artifact '" + id + "' requires must be an array")
      evaluatedReqs = []
    }
    let reqs = evaluatedReqs
    for req in reqs {
      if req != "source" and !artifactSet[req] {
        push(errors, "Artifact '" + id + "' requires unknown '" + req + "'")
      }
    }

    let rawProduces = spec and spec.produces or []
    let evaluatedProduces = type(rawProduces) == "fn" and rawProduces(needs) or rawProduces
    if type(evaluatedProduces) != "array" {
      push(errors, "Artifact '" + id + "' produces must be an array")
      evaluatedProduces = []
    }
    let producers = evaluatedProduces
    for passName in producers {
      if !PASS_DEFS[passName] {
        push(errors, "Artifact '" + id + "' produced by unknown pass '" + passName + "'")
      }
    }
  }

  if len(errors) == 0 { return true }

  Lx.stderr.println("Artifact spec validation failed:")
  for err in errors { Lx.stderr.println("  " + err) }
  false
}

fn planArtifactGraph(artifactId, needs) {
  fn walk(id, visited, graph) {
    if visited[id] { return }
    visited[id] = true
    let reqs = artifactRequires(id, needs)
    graph[id] = reqs
    for req in reqs { walk(req, visited, graph) }
  }

  let graph = .{}
  let visited = .{}
  walk(artifactId, visited, graph)
  graph
}

fn capabilityProviders() {
  let providers = .{}
  for passName in PASS_ORDER {
    let pass = PASS_DEFS[passName]
    let caps = pass and pass.provides or []
    for cap in caps {
      if !providers[cap] { providers[cap] = [] }
      push(providers[cap], passName)
    }
  }
  providers
}

fn derivePassPlan(graph, needs) {
  let required = .{}
  let artifactIds = keys(graph)
  for artifactId in artifactIds {
    let produced = artifactProduces(artifactId, needs)
    for passName in produced {
      if passEnabled(passName, needs) { required[passName] = true }
    }
  }

  let providers = capabilityProviders()

  let changed = true
  for changed {
    changed = false
    let provided = .{}
    for passName in PASS_ORDER {
      if required[passName] and passEnabled(passName, needs) {
        let pass = PASS_DEFS[passName]
        let caps = pass and pass.provides or []
        for cap in caps { provided[cap] = true }
      }

      if required[passName] and passEnabled(passName, needs) {
        let pass = PASS_DEFS[passName]
        let reqs = pass and pass.requires or []
        for cap in reqs {
          if !provided[cap] {
            let candidates = providers[cap] or []
            let provider = nil
            for candidate in candidates {
              if passEnabled(candidate, needs) {
                provider = candidate
                break
              }
            }
            if provider and !required[provider] {
              required[provider] = true
              changed = true
            }
          }
        }
      }
    }
  }

  collect passName in PASS_ORDER {
    if required[passName] and passEnabled(passName, needs) { passName } else { continue }
  }
}

fn trimPassPlan(passPlan, stopAfter) {
  if !stopAfter { return passPlan }
  let out = []
  for passName in passPlan {
    push(out, passName)
    if passName == stopAfter { break }
  }
  out
}

fn hasRequiredPasses(result, passNames) {
  if !result or !result.passes { return false }
  for passName in passNames {
    let passResult = result.passes[passName]
    if !passResult or passResult.success != true {
      return false
    }
  }
  true
}

// ========================================
// Driver Factory
// ========================================

fn make(opts) {
  let cache = .{}
  let compiledModules = []  // Track compilation order
  let loadSource = opts["loadSource"]

  // Profile support: profile sets defaults, explicit flags override
  // Use `opts["..."]` for optional keys so callers can omit them.
  let profileName = opts["profile"] or "default"
  let profileDefaults = getProfile(profileName)
  let defaultTarget = getDefaultTarget(profileName)

  if !profileDefaults {
    // Unknown profile - error
    Lx.stderr.println("Error: Unknown profile '" + profileName + "'")
    Lx.stderr.println("Available profiles: default, typecheck, query")
    return nil
  }

  // Apply profile defaults, then override with explicit flags
  // Check if flag is explicitly set (not nil), if so use it, else use profile default
  let withLower = nil
  let explicitWithLower = opts["withLower"]
  if explicitWithLower != nil {
    withLower = explicitWithLower
  } else {
    withLower = profileDefaults.withLower
  }

  let withTypecheck = nil
  let explicitWithTypecheck = opts["withTypecheck"]
  if explicitWithTypecheck != nil {
    withTypecheck = explicitWithTypecheck
  } else {
    withTypecheck = profileDefaults.withTypecheck
  }

  let withAnf = nil
  let explicitWithAnf = opts["withAnf"]
  if explicitWithAnf != nil {
    withAnf = explicitWithAnf
  } else {
    withAnf = profileDefaults.withAnf
  }

  let withAnfInline = nil
  let explicitWithAnfInline = opts["withAnfInline"]
  if explicitWithAnfInline != nil {
    withAnfInline = explicitWithAnfInline
  } else {
    withAnfInline = profileDefaults.withAnfInline
  }

  let withLowerIntrinsics = nil
  let explicitWithLowerIntrinsics = opts["withLowerIntrinsics"]
  if explicitWithLowerIntrinsics != nil {
    withLowerIntrinsics = explicitWithLowerIntrinsics
  } else {
    withLowerIntrinsics = profileDefaults.withLowerIntrinsics
  }

  // DCE is on by default
  let withDce = opts["withDce"] != false

  // Optional import overrides (used when compiling transitive imports).
  // Defaults to top-level behavior unless overridden.
  let withImportLower = opts["withImportLower"]
  if withImportLower == nil { withImportLower = withLower }

  let planNeeds = .{
    withLower: withLower == true,
    withAnf: withAnf == true,
    withAnfInline: withAnfInline == true,
    withLowerIntrinsics: withLowerIntrinsics == true,
    withTypecheck: withTypecheck == true,
    withDce: withDce == true,
  }
  if !validateArtifactSpec(planNeeds) { return nil }

  // Debug flags (optional)
  let debug = opts["debug"]
  let wholeProgramTypecheckDone = false
  let wholeProgramTypecheckStamp = nil
  let wholeProgramDceDone = false
  let wholeProgramDceStamp = nil
  let wholeProgramDceArtifact = nil  // Cached artifact for ANALYSIS_DCE_WHOLE_PROGRAM
  let compileDepth = 0

  fn runWholeProgramTypecheck(entryResult) {
    // Typecheck in reverse discovery order so imports are processed first.

    // Check if we need to rerun based on programStamp
    let currentProgramStamp = computeProgramStamp(compiledModules)
    if wholeProgramTypecheckDone and wholeProgramTypecheckStamp == currentProgramStamp {
      return entryResult  // Already done with same module graph
    }

    let programExports = .{}

    for let i = len(compiledModules) - 1; i >= 0; i = i - 1 {
      let path = compiledModules[i]
      let r = cache[path]
      if !r or r.status != "done" { continue }
      let passes = r.passes or .{}
      let resolveResult = passes.resolve
      if !resolveResult or resolveResult.success != true { continue }

      let ast = getFinalAst(passes)
      if !ast { continue }

      let enumInfo = getFinalEnumInfo(passes)

      let tc = typecheck(ast, resolveResult, .{
        enumInfo: enumInfo,
        program: .{ exports: programExports },
      }) or .{ success: false, errors: ["typecheck returned nil"], types: .{}, typeVarBindings: .{} }

      // Attach as a non-fatal pass result for tooling to inspect.
      passes.typecheck = tc
      r.passes = passes
      if r.passOrder { push(r.passOrder, "typecheck") }

      // Record module's export type (type of last expression) for downstream imports.
      if ast.type == NODE.Block and ast.expressions and len(ast.expressions) > 0 {
        let last = ast.expressions[len(ast.expressions) - 1]
        if last and tc.types and tc.types[last.id] {
          programExports[path] = tc.types[last.id]
        }
      }
    }

    wholeProgramTypecheckDone = true
    wholeProgramTypecheckStamp = currentProgramStamp
    entryResult
  }

  fn runWholeProgramDce(entryResult) {
    // DEPRECATED: This function is no longer used in the artifact-driven pipeline.
    // Whole-program DCE is now handled via:
    //   buildProgram(entry, ARTIFACT.ANALYSIS_DCE_WHOLE_PROGRAM)
    //   buildModule(path, ARTIFACT.ANALYSIS_DCE_FINAL)
    //
    // This function mutates local DCE results in-place, which violates the
    // artifact model's invariant that local DCE should remain pristine.
    // Kept for reference only - should be removed in a future cleanup.

    // Check if we need to rerun based on programStamp
    let currentProgramStamp = computeProgramStamp(compiledModules)
    if wholeProgramDceDone and wholeProgramDceStamp == currentProgramStamp {
      return entryResult  // Already done with same module graph
    }

    // Step 1: Collect usedImportProperties from all modules
    // Build: usedExportsPerModule[modulePath] = { propName: true, ... }
    let usedExportsPerModule = .{}

    for path in compiledModules {
      let r = cache[path]
      if !r or r.status != "done" { continue }
      let passes = r.passes or .{}
      let dceResult = passes.dce
      if !dceResult or !dceResult.success { continue }

      let usedProps = dceResult.usedImportProperties or .{}
      for importPath in keys(usedProps) {
        let props = usedProps[importPath]
        if !usedExportsPerModule[importPath] {
          usedExportsPerModule[importPath] = .{}
        }
        // Merge used properties
        for propName in keys(props) {
          usedExportsPerModule[importPath][propName] = true
        }
      }
    }

    // Step 2: For each module, find unused exports and mark them dead
    for path in compiledModules {
      let r = cache[path]
      if !r or r.status != "done" { continue }
      let passes = r.passes or .{}
      let dceResult = passes.dce
      if !dceResult or !dceResult.success { continue }

      // Get the module's AST to find its exports (last expression)
      let ast = getFinalAst(passes)
      if !ast { continue }

      // Find the last expression (module's exports)
      if ast.type == NODE.Block and ast.expressions and len(ast.expressions) > 0 {
        let lastExpr = ast.expressions[len(ast.expressions) - 1]
        if lastExpr and lastExpr.type == NODE.Hashmap {
          // Module exports a hashmap - check which exports are unused
          let usedProps = usedExportsPerModule[path] or .{}
          let entries = lastExpr.entries or []

          for entry in entries {
            if !entry { continue }
            let key = entry.key
            let keyName = key and (key.name or key.value or key.lexeme)
            if !keyName { continue }

            if !usedProps[keyName] {
              // This export is unused - mark the value as dead
              if entry.value and entry.value.id {
                dceResult.deadNodes[entry.value.id] = true
                if !dceResult.unusedExports {
                  dceResult.unusedExports = .{}
                }
                dceResult.unusedExports[keyName] = "unused export"
              }
            }
          }
        }
      }
    }

    wholeProgramDceDone = true
    wholeProgramDceStamp = currentProgramStamp
    entryResult
  }

  fn compileModuleInternal(path, targetArtifact) {
    let isImport = compileDepth > 1
    let effectiveWithLower = isImport and withImportLower or withLower
    let effectiveWithAnf = withAnf
    let effectiveWithAnfInline = withAnfInline
    let effectiveWithLowerIntrinsics = withLowerIntrinsics
    let effectiveWithTypecheck = withTypecheck
    let effectiveWithDce = withDce
    // If lower is disabled, downstream passes depending on lowered AST must be disabled.
    if effectiveWithLower == false {
      effectiveWithAnf = false
      effectiveWithAnfInline = false
      effectiveWithLowerIntrinsics = false
      effectiveWithTypecheck = false
    }
    if effectiveWithAnf == false {
      effectiveWithAnfInline = false
      effectiveWithLowerIntrinsics = false
    }

    let needs = .{
      withLower: effectiveWithLower == true,
      withAnf: effectiveWithAnf == true,
      withAnfInline: effectiveWithAnfInline == true,
      withLowerIntrinsics: effectiveWithLowerIntrinsics == true,
      withTypecheck: effectiveWithTypecheck == true,
      withDce: effectiveWithDce == true,
    }

    let target = targetArtifact or defaultTarget
    let graph = planArtifactGraph(target, needs)
    let passNames = derivePassPlan(graph, needs)
    if debug and debug.stopAfter {
      passNames = trimPassPlan(passNames, debug.stopAfter)
    }

    // Load source to compute hash for cache validation
    let source = nil
    if loadSource {
      source = loadSource(path)
    }

    if !source {
      // Source loading failed - represent as failed parse pass
      let result = .{
        status: "failed",
        success: false,
        path: path,
        failedPass: "parse",
        passOrder: ["parse"],
        passes: .{
          parse: .{
            success: false,
            errors: ["Failed to load source: " + path],
          },
        },
      }
      cache[path] = result
      return result
    }

    // Compute astStamp including source hash
    let sourceHash = simpleStringHash(source)
    let currentStamp = computeAstStamp(needs, sourceHash)

    // Check cache first
    let cached = cache[path]
    if cached {
      // Respect "compiling" sentinel for circular import detection.
      if cached.status != "done" and cached.status != "failed" {
        return cached
      }
      // Check if cached result matches current configuration via stamp
      // This now includes source content, so file edits invalidate cache
      if cached.astStamp == currentStamp and hasRequiredPasses(cached, passNames) {
        return cached
      }
      // Otherwise: upgrade/downgrade by recompiling with current needs.
    }

    // Track compilation (first time only)
    push(compiledModules, path)
    // Graph changed; any previous whole-program results are stale.
    wholeProgramTypecheckDone = false
    wholeProgramDceArtifact = nil  // Invalidate cached whole-program DCE

    // Mark as compiling (for circular import detection)
    cache[path] = .{
      status: "compiling",
      path: path,
    }

    // ========================================
    // Run Pipeline
    // ========================================

    // Build context for passes
    let ctx = .{
      importCache: cache,
      // Use the public wrapper so nested imports bump compileDepth, enabling
      // per-import build options like `withImportLower`.
      compileModule: compileModule,
      opts: .{
        withLower: effectiveWithLower,
        withAnf: effectiveWithAnf,
        withAnfInline: effectiveWithAnfInline,
        withLowerIntrinsics: effectiveWithLowerIntrinsics,
        withTypecheck: effectiveWithTypecheck,
        withDce: effectiveWithDce,
      },
      debug: debug or .{},
    }

    // Build initial state
    let state = .{
      path: path,
      source: source,
      ast: nil,
      nextNodeId: 1,
      passes: .{},
    }

    // Execute passes
    let passList = collect passName in passNames {
      let pass = PASS_DEFS[passName]
      if pass { pass } else { continue }
    }
    let pipelineResult = pipeline.runPasses(passList, ctx, state)

    // Build result with pipeline fields
    let result = .{
      // Core fields
      status: pipelineResult.status,
      success: pipelineResult.success,
      path: path,
      failedPass: pipelineResult.failedPass,
      buildOpts: needs,

      // Pipeline fields
      passOrder: pipelineResult.passOrder,
      passes: pipelineResult.passes,

      // Cache invalidation
      astStamp: currentStamp,
    }

    cache[path] = result
    return result
  }

  fn compileModuleForArtifact(path, artifactId) {
    compileDepth = compileDepth + 1
    let isTop = compileDepth == 1
    let result = compileModuleInternal(path, artifactId)
    compileDepth = compileDepth - 1

    if isTop and withTypecheck != false and !wholeProgramTypecheckDone {
      result = runWholeProgramTypecheck(result)
    }

    // Whole-program DCE is now handled via the artifact API:
    // buildModule(path, ARTIFACT.ANALYSIS_DCE_FINAL) computes it on-demand
    // This preserves local DCE as pristine and derives final DCE without mutation.

    result
  }

  fn compileModule(path) {
    compileModuleForArtifact(path, defaultTarget)
  }

  fn planPasses(artifactId) {
    let needs = .{
      withLower: withLower == true,
      withAnf: withAnf == true,
      withAnfInline: withAnfInline == true,
      withLowerIntrinsics: withLowerIntrinsics == true,
      withTypecheck: withTypecheck == true,
      withDce: withDce == true,
    }

    let graph = planArtifactGraph(artifactId or defaultTarget, needs)
    derivePassPlan(graph, needs)
  }

  fn planPassesDetailed(artifactId) {
    let needs = .{
      withLower: withLower == true,
      withAnf: withAnf == true,
      withAnfInline: withAnfInline == true,
      withLowerIntrinsics: withLowerIntrinsics == true,
      withTypecheck: withTypecheck == true,
      withDce: withDce == true,
    }

    let graph = planArtifactGraph(artifactId or defaultTarget, needs)
    let required = derivePassPlan(graph, needs)
    let requiredSet = .{}
    for passName in required { requiredSet[passName] = true }

    collect passName in PASS_ORDER {
      .{
        name: passName,
        enabled: passEnabled(passName, needs),
        required: requiredSet[passName] == true,
      }
    }
  }

  fn planArtifactGraphForTarget(artifactId) {
    let needs = .{
      withLower: withLower == true,
      withAnf: withAnf == true,
      withAnfInline: withAnfInline == true,
      withLowerIntrinsics: withLowerIntrinsics == true,
      withTypecheck: withTypecheck == true,
      withDce: withDce == true,
    }
    planArtifactGraph(artifactId or defaultTarget, needs)
  }

  // ========================================
  // Backend Artifact Producers
  // ========================================

  fn produceFastcheck(path) {
    // Produce ARTIFACT.ANALYSIS_FASTCHECK for a module
    let result = cache[path]
    if !result or result.status != "done" { return nil }

    // Check if already computed
    if result.fastcheckResult { return result.fastcheckResult }

    let passes = result.passes or .{}
    let ast = getFinalAst(passes)
    let enumInfo = getFinalEnumInfo(passes)
    let resolveResult = passes.resolve

    if !ast or !resolveResult { return nil }

    let fc = fastcheck(ast, resolveResult, .{ enumInfo: enumInfo })
    result.fastcheckResult = fc
    fc
  }

  fn produceCodegen(path) {
    // Produce ARTIFACT.BYTECODE_FUNCTION for a module
    let result = cache[path]
    if !result or result.status != "done" { return nil }

    // Check if already computed
    if result.codegenResult and result.codegenResult.function {
      return result.codegenResult.function
    }

    let passes = result.passes or .{}
    let ast = getFinalAst(passes)
    let enumInfo = getFinalEnumInfo(passes)
    let resolveResult = passes.resolve

    if !ast or !resolveResult { return nil }

    // Ensure fastcheck is available
    let fc = produceFastcheck(path)
    if !fc { return nil }

    // Get final DCE (includes whole-program DCE if at top level)
    let finalDce = buildModule(path, ARTIFACT.ANALYSIS_DCE_FINAL)
    let deadNodes = finalDce and finalDce.deadNodes or .{}

    // Recursive codegenModule callback for imports
    let codegenModule = fn(modulePath) {
      produceCodegen(modulePath)
    }

    let cg = codegen(ast, resolveResult, .{
      codegenModule: codegenModule,
      enumInfo: enumInfo,
      fastcheck: fc,
      dceResult: .{ deadNodes: deadNodes },
    })

    result.codegenResult = cg
    if !cg.success { return nil }

    cg.function
  }

  fn produceVerify(path) {
    // Produce ARTIFACT.BYTECODE_VERIFIED for a module
    let result = cache[path]
    if !result or result.status != "done" { return nil }

    // Check if already computed
    if result.verifyResult and result.verifyResult.success {
      // Return the function (verify just validates, doesn't transform)
      let cg = result.codegenResult
      if cg and cg.function { return cg.function }
      return nil
    }

    // Ensure codegen is available
    let function = produceCodegen(path)
    if !function { return nil }

    let verifyResult = verify.verifyFunction(function)
    result.verifyResult = verifyResult

    if !verifyResult.success { return nil }

    function
  }

  // ========================================
  // Artifact Build API
  // ========================================

  fn buildModule(path, artifactId) {
    // Build a specific artifact for a module.
    // This is the artifact-driven compilation API.
    //
    // Args:
    //   path: Module path
    //   artifactId: One of ARTIFACT.* constants
    //
    // Returns: Artifact payload or nil on error

    // First, ensure the module is compiled
    let result = compileModuleForArtifact(path, artifactId)
    if !result or result.status != "done" {
      return nil
    }

    let passes = result.passes or .{}

    // Map artifact IDs to their sources
    if artifactId == ARTIFACT.AST_FINAL {
      return getFinalAst(passes)
    }

    if artifactId == ARTIFACT.ANALYSIS_RESOLVE {
      return passes.resolve
    }

    if artifactId == ARTIFACT.ANALYSIS_DCE_LOCAL {
      return passes.dce
    }

    if artifactId == ARTIFACT.ANALYSIS_TYPECHECK {
      return passes.typecheck
    }

    if artifactId == ARTIFACT.ANALYSIS_FASTCHECK {
      return produceFastcheck(path)
    }

    if artifactId == ARTIFACT.BYTECODE_FUNCTION {
      return produceCodegen(path)
    }

    if artifactId == ARTIFACT.BYTECODE_VERIFIED {
      return produceVerify(path)
    }

    if artifactId == ARTIFACT.ANALYSIS_DCE_FINAL {
      // Derive final DCE by combining local DCE with whole-program DCE
      // This is the DCE result that codegen should use

      let localDce = passes.dce
      if !localDce { return nil }

      // If whole-program DCE is disabled, just use local DCE
      if !withDce {
        return localDce
      }

      // Get whole-program DCE artifact (this triggers whole-program analysis)
      // We need to find the entry point - for imports, we can't run whole-program DCE
      // So we only apply whole-program DCE at the top level
      if compileDepth > 1 {
        // This is an import - use local DCE only
        return localDce
      }

      // At top level - compute whole-program DCE
      let wholeProgramDce = buildProgram(path, ARTIFACT.ANALYSIS_DCE_WHOLE_PROGRAM)
      if !wholeProgramDce or !wholeProgramDce.success {
        // Whole-program DCE failed - use local DCE
        return localDce
      }

      // Merge local DCE with whole-program findings
      let finalDce = .{
        success: true,
        deadNodes: .{},
        usedImportProperties: localDce.usedImportProperties,
      }

      // Copy local dead nodes
      let localDeadNodes = localDce.deadNodes or .{}
      for nodeId in keys(localDeadNodes) {
        finalDce.deadNodes[nodeId] = true
      }

      // Add dead nodes from unused exports
      let usedExports = wholeProgramDce.usedExportsPerModule[path] or .{}
      let ast = getFinalAst(passes)
      if ast and ast.type == NODE.Block and ast.expressions and len(ast.expressions) > 0 {
        let lastExpr = ast.expressions[len(ast.expressions) - 1]
        if lastExpr and lastExpr.type == NODE.Hashmap {
          let entries = lastExpr.entries or []
          for entry in entries {
            if !entry { continue }
            let key = entry.key
            let keyName = key and (key.name or key.value or key.lexeme)
            if !keyName { continue }

            if !usedExports[keyName] {
              // This export is unused - mark its value as dead
              if entry.value and entry.value.id {
                finalDce.deadNodes[entry.value.id] = true
              }
            }
          }
        }
      }

      return finalDce
    }

    // Unknown artifact
    nil
  }

  fn buildProgram(entryPath, artifactId) {
    // Build a program-level artifact.
    // Program-level artifacts require all modules to be compiled.
    //
    // Args:
    //   entryPath: Entry module path
    //   artifactId: One of ARTIFACT.PROGRAM_* constants
    //
    // Returns: Artifact payload or nil on error

    // Compile the entry module (this recursively compiles all imports)
    let compileTarget =
      artifactId == ARTIFACT.ANALYSIS_DCE_WHOLE_PROGRAM and ARTIFACT.ANALYSIS_DCE_LOCAL or
      artifactId == ARTIFACT.PROGRAM_MODULE_GRAPH and ARTIFACT.ANALYSIS_RESOLVE or
      defaultTarget

    let entryResult = compileModuleForArtifact(entryPath, compileTarget)
    if !entryResult or entryResult.status != "done" {
      return nil
    }

    if artifactId == ARTIFACT.PROGRAM_MODULE_GRAPH {
      // Return the compiled module graph
      return .{
        entry: entryPath,
        modules: compiledModules,
        cache: cache,
      }
    }

    if artifactId == ARTIFACT.ANALYSIS_DCE_WHOLE_PROGRAM {
      // Compute whole-program DCE facts by analyzing all modules
      // This artifact represents the complete program-level dead code analysis

      // Ensure all modules are compiled
      compileModuleForArtifact(entryPath, ARTIFACT.ANALYSIS_DCE_LOCAL)

      // Check if we have a cached result
      let programStamp = computeProgramStamp(compiledModules)
      if wholeProgramDceArtifact and wholeProgramDceArtifact.programStamp == programStamp {
        return wholeProgramDceArtifact
      }

      // Build usedExportsPerModule: { modulePath: { exportName: true } }
      let usedExportsPerModule = .{}

      for path in compiledModules {
        let r = cache[path]
        if !r or r.status != "done" { continue }
        let passes = r.passes or .{}
        let dceResult = passes.dce
        if !dceResult or !dceResult.success { continue }

        // Collect used imports from this module
        let usedProps = dceResult.usedImportProperties or .{}
        for importPath in keys(usedProps) {
          let props = usedProps[importPath]
          if !usedExportsPerModule[importPath] {
            usedExportsPerModule[importPath] = .{}
          }
          for propName in keys(props) {
            usedExportsPerModule[importPath][propName] = true
          }
        }
      }

      // Build and cache the whole-program DCE artifact
      let artifact = .{
        success: true,
        programStamp: programStamp,
        usedExportsPerModule: usedExportsPerModule,
        modules: compiledModules,
      }
      wholeProgramDceArtifact = artifact
      artifact
    }

    // Unknown artifact
    nil
  }

  .{
    cache: cache,
    compiledModules: compiledModules,
    loadSource: loadSource,
    withLower: withLower,
    withTypecheck: withTypecheck,
    withAnf: withAnf,
    withAnfInline: withAnfInline,
    debug: debug,
    compileModule: compileModule,
    planPasses: planPasses,
    planPassesDetailed: planPassesDetailed,
    planArtifactGraph: planArtifactGraphForTarget,
    buildModule: buildModule,
    buildProgram: buildProgram,
  }
}

// ========================================
// Module Exports
// ========================================

.{
  make,
  ARTIFACT,
  getFinalAst,
  getFinalEnumInfo,
}
