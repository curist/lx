let .{ TOKEN, NODE } = import "src/types.lx"
let initScanner = import "src/passes/frontend/scanner.lx"

let PREC = enum {
  NONE,        // 0
  ASSIGNMENT,  // =
  OR,          // or
  AND,         // and
  BIT_OR,      // |
  BIT_XOR,     // ^
  BIT_AND,     // &
  EQUALITY,    // == !=
  COMPARISON,  // < > <= >=
  BIT_SHIFT,   // << >>
  TERM,        // + -
  FACTOR,      // * /
  PIPELINE,    // ->
  UNARY,       // ! -
  CALL,        // . () []
  PRIMARY,
}

// Token types that can be used as hashmap/object keys
// This explicitly allows keywords in key positions
let KEY_TOKENS = .{
  [TOKEN.IDENTIFIER]: true,
  [TOKEN.IF]: true,
  [TOKEN.ELSE]: true,
  [TOKEN.FOR]: true,
  [TOKEN.FN]: true,
  [TOKEN.LET]: true,
  [TOKEN.ENUM]: true,
  [TOKEN.RETURN]: true,
  [TOKEN.BREAK]: true,
  [TOKEN.CONTINUE]: true,
  [TOKEN.IMPORT]: true,
  [TOKEN.IN]: true,
  [TOKEN.COLLECT]: true,
  [TOKEN.AND]: true,
  [TOKEN.OR]: true,
  [TOKEN.TRUE]: true,
  [TOKEN.FALSE]: true,
  [TOKEN.NIL]: true,
}

// Token types that are good breakpoints for error recovery
let SYNC_BREAKPOINTS = .{
  [TOKEN.FN]: true,
  [TOKEN.LET]: true,
  [TOKEN.ENUM]: true,
  [TOKEN.FOR]: true,
  [TOKEN.IF]: true,
  [TOKEN.RETURN]: true,
  [TOKEN.IMPORT]: true,
  [TOKEN.DOT_BRACE]: true,
}

// Node ID counter - reset at start of each parse()
let nodeIdCounter = 0

// AST Node constructors
fn Node(type, filename, token) {
  // Scanner's token.col points AFTER the token
  // So: startCol = col - length, endCol = col
  let tokenLen = len(token.lexeme)
  let startCol = token.col - tokenLen
  // Clamp to 0 in case of edge cases
  if startCol < 0 { startCol = 0 }

  nodeIdCounter = nodeIdCounter + 1

  .{
    id: nodeIdCounter,
    type: type,
    filename: filename,
    line: token.line,
    col: startCol,
    endLine: token.line,
    endCol: token.col,
  }
}

fn NumberNode(filename, token) {
  let node = Node(NODE.Number, filename, token)
  node.value = token.literal
  node.lexeme = token.lexeme
  node
}

fn StringNode(filename, token) {
  let node = Node(NODE.String, filename, token)
  node.value = token.literal
  node.lexeme = token.lexeme
  node
}

fn BoolNode(filename, token) {
  let node = Node(NODE.Bool, filename, token)
  node.value = token.type == TOKEN.TRUE
  node.lexeme = token.lexeme
  node
}

fn NilNode(filename, token) {
  let node = Node(NODE.Nil, filename, token)
  node.lexeme = token.lexeme
  node
}

fn IdentifierNode(filename, token) {
  let node = Node(NODE.Identifier, filename, token)
  node.name = token.lexeme
  node.lexeme = token.lexeme
  node
}

fn BinaryNode(filename, left, operator, right) {
  // Operator token.col points after the operator
  let opLen = len(operator.lexeme)
  let opStartCol = operator.col - opLen
  if opStartCol < 0 { opStartCol = 0 }

  nodeIdCounter = nodeIdCounter + 1

  .{
    id: nodeIdCounter,
    type: NODE.Binary,
    filename: filename,
    line: left.line,
    col: left.col,  // Start from left operand
    endLine: right and right.endLine or operator.line,
    endCol: right and right.endCol or operator.col,
    left: left,
    operator: .{
      type: operator.type,
      lexeme: operator.lexeme,
      line: operator.line,
      col: opStartCol,  // Adjusted operator position
    },
    right: right,
  }
}

fn UnaryNode(filename, operator, operand) {
  // Operator token.col points after the operator
  let opLen = len(operator.lexeme)
  let opStartCol = operator.col - opLen
  if opStartCol < 0 { opStartCol = 0 }

  nodeIdCounter = nodeIdCounter + 1

  .{
    id: nodeIdCounter,
    type: NODE.Unary,
    filename: filename,
    line: operator.line,
    col: opStartCol,  // Start from operator
    endLine: operand and operand.endLine or operator.line,
    endCol: operand and operand.endCol or operator.col,
    operator: .{
      type: operator.type,
      lexeme: operator.lexeme,
      line: operator.line,
      col: opStartCol,  // Adjusted operator position
    },
    operand: operand,
  }
}

fn LogicalNode(filename, left, operator, right) {
  // Operator token.col points after the operator
  let opLen = len(operator.lexeme)
  let opStartCol = operator.col - opLen
  if opStartCol < 0 { opStartCol = 0 }

  nodeIdCounter = nodeIdCounter + 1

  .{
    id: nodeIdCounter,
    type: NODE.Logical,
    filename: filename,
    line: left.line,
    col: left.col,  // Start from left operand
    endLine: right and right.endLine or operator.line,
    endCol: right and right.endCol or operator.col,
    left: left,
    operator: .{
      type: operator.type,
      lexeme: operator.lexeme,
      line: operator.line,
      col: opStartCol,  // Adjusted operator position
    },
    right: right,
  }
}

fn GroupingNode(filename, expr, startToken, endToken) {
  let node = Node(NODE.Grouping, filename, startToken)
  node.expression = expr
  node.endLine = endToken.line
  node.endCol = endToken.col
  node
}

fn LetNode(filename, startToken, nameToken, init) {
  let node = Node(NODE.Let, filename, startToken)
  node.name = IdentifierNode(filename, nameToken)
  node.init = init
  if init {
    node.endLine = init.endLine
    node.endCol = init.endCol
  } else {
    node.endLine = nameToken.line
    node.endCol = nameToken.col
  }
  node
}

fn LetDestructureNode(filename, startToken, bindings, init) {
  let node = Node(NODE.LetDestructure, filename, startToken)
  node.bindings = bindings
  node.init = init
  if init {
    node.endLine = init.endLine
    node.endCol = init.endCol
  }
  node
}

fn BlockNode(filename, startToken, expressions, endToken) {
  let node = Node(NODE.Block, filename, startToken)
  node.expressions = expressions
  node.endLine = endToken.line
  node.endCol = endToken.col
  node
}

fn FunctionNode(filename, startToken, name, params, body, endToken) {
  let node = Node(NODE.Function, filename, startToken)
  node.name = name
  node.params = params
  node.body = body
  node.endLine = endToken.line
  node.endCol = endToken.col
  node
}

fn CallNode(filename, callee, args, endToken) {
  // endToken is the closing paren ")"
  // Its col points after it, which is exactly where the call ends
  nodeIdCounter = nodeIdCounter + 1

  .{
    id: nodeIdCounter,
    type: NODE.Call,
    filename: filename,
    line: callee.line,
    col: callee.col,
    endLine: endToken.line,
    endCol: endToken.col,  // Already points after ")"
    callee: callee,
    args: args,
  }
}

fn ArrowNode(filename, left, right, arrowToken) {
  // Start span from left operand (like Binary/Logical/Call/etc)
  // Calculate arrow operator position
  let opLen = len(arrowToken.lexeme)
  let opStartCol = arrowToken.col - opLen
  if opStartCol < 0 { opStartCol = 0 }

  nodeIdCounter = nodeIdCounter + 1

  .{
    id: nodeIdCounter,
    type: NODE.Arrow,
    filename: filename,
    line: left.line,
    col: left.col,
    endLine: right.endLine,
    endCol: right.endCol,
    left: left,
    operator: .{
      type: arrowToken.type,
      lexeme: arrowToken.lexeme,
      line: arrowToken.line,
      col: opStartCol,
    },
    right: right,
  }
}

fn IfNode(filename, startToken, condition, thenBranch, elseBranch) {
  let node = Node(NODE.If, filename, startToken)
  node.condition = condition
  node.then = thenBranch
  node.else = elseBranch
  if elseBranch {
    node.endLine = elseBranch.endLine
    node.endCol = elseBranch.endCol
  } else {
    node.endLine = thenBranch.endLine
    node.endCol = thenBranch.endCol
  }
  node
}

fn ForNode(filename, startToken, init, condition, update, body, endToken) {
  let node = Node(NODE.For, filename, startToken)
  node.init = init
  node.condition = condition
  node.update = update
  node.body = body
  node.endLine = endToken.line
  node.endCol = endToken.col
  node
}

fn ForInNode(filename, startToken, valueBinder, indexBinder, iterable, body, endToken) {
  let node = Node(NODE.ForIn, filename, startToken)
  node.valueBinder = valueBinder
  node.indexBinder = indexBinder
  node.iterable = iterable
  node.body = body
  node.endLine = endToken.line
  node.endCol = endToken.col
  node
}

fn CollectNode(filename, startToken, init, condition, update, body, endToken) {
  let node = Node(NODE.Collect, filename, startToken)
  node.init = init
  node.condition = condition
  node.update = update
  node.body = body
  node.endLine = endToken.line
  node.endCol = endToken.col
  node
}

fn CollectInNode(filename, startToken, valueBinder, indexBinder, iterable, body, endToken) {
  let node = Node(NODE.CollectIn, filename, startToken)
  node.valueBinder = valueBinder
  node.indexBinder = indexBinder
  node.iterable = iterable
  node.body = body
  node.endLine = endToken.line
  node.endCol = endToken.col
  node
}

fn ReturnNode(filename, startToken, value) {
  let node = Node(NODE.Return, filename, startToken)
  node.value = value
  if value {
    node.endLine = value.endLine
    node.endCol = value.endCol
  }
  node
}

fn BreakNode(filename, startToken) {
  Node(NODE.Break, filename, startToken)
}

fn ContinueNode(filename, token) {
  Node(NODE.Continue, filename, token)
}

fn ArrayNode(filename, startToken, elements, endToken) {
  let node = Node(NODE.Array, filename, startToken)
  node.elements = elements
  node.endLine = endToken.line
  node.endCol = endToken.col
  node
}

fn HashmapNode(filename, startToken, pairs, endToken) {
  let node = Node(NODE.Hashmap, filename, startToken)
  node.pairs = pairs
  node.endLine = endToken.line
  node.endCol = endToken.col
  node
}

fn IndexNode(filename, object, index, endToken) {
  // endToken is the closing bracket "]"
  // Its col points after it
  nodeIdCounter = nodeIdCounter + 1

  .{
    id: nodeIdCounter,
    type: NODE.Index,
    filename: filename,
    line: object.line,
    col: object.col,
    endLine: endToken.line,
    endCol: endToken.col,  // Already points after "]"
    object: object,
    index: index,
  }
}

fn DotNode(filename, object, property, endToken) {
  // property is already a Node with correct positions
  nodeIdCounter = nodeIdCounter + 1

  .{
    id: nodeIdCounter,
    type: NODE.Dot,
    filename: filename,
    line: object.line,
    col: object.col,
    endLine: property.endLine,
    endCol: property.endCol,
    object: object,
    property: property,
  }
}

fn AssignmentNode(filename, target, value, equalToken) {
  nodeIdCounter = nodeIdCounter + 1

  .{
    id: nodeIdCounter,
    type: NODE.Assignment,
    filename: filename,
    line: target.line,
    col: target.col,
    endLine: value.endLine,
    endCol: value.endCol,
    target: target,
    value: value,
  }
}

fn ImportNode(filename, startToken, path) {
  let node = Node(NODE.Import, filename, startToken)
  node.path = path
  node.endLine = path.endLine
  node.endCol = path.endCol
  node
}

fn StringKeyNodeFromToken(filename, token) {
  // Create a String node from a token's lexeme (for dot/hashmap keys)
  let tokenLen = len(token.lexeme)
  let startCol = token.col - tokenLen
  if startCol < 0 { startCol = 0 }

  nodeIdCounter = nodeIdCounter + 1

  .{
    id: nodeIdCounter,
    type: NODE.String,
    filename: filename,
    line: token.line,
    col: startCol,
    endLine: token.line,
    endCol: token.col,
    value: token.lexeme,
    lexeme: token.lexeme,
  }
}

fn parse(src, filename) {
  let scanner = initScanner(src)

  // Reset node ID counter for this module
  nodeIdCounter = 0

  let parser = .{
    current: 0,
    previous: 0,
    hadError: false,
    panicMode: false,
    errors: [],
    enumInfo: .{}, // nodeId -> { members: [{ name, value }] }
  }

  fn errorAt(token, message) {
    if parser.panicMode {
      return
    }
    parser.panicMode = true

    // Calculate token start column (scanner's col points AFTER token)
    let tokenCol = token.col
    if token.type != TOKEN.EOF {
      let tokenLen = len(token.lexeme)
      tokenCol = token.col - tokenLen
      if tokenCol < 0 { tokenCol = 0 }
    }

    let errorMsg = join([
      "[", filename, ":L", token.line, ":C", tokenCol, "]",
      if token.type == TOKEN.EOF {
        " at end"
      } else if token.type == TOKEN.ERROR {
        ""
      } else {
        " at '" + token.lexeme + "'"
      },
      ": ", message,
    ], "")

    push(parser.errors, errorMsg)
    parser.hadError = true
  }

  fn error(message) {
    errorAt(parser.previous, message)
  }

  fn errorAtCurrent(message) {
    errorAt(parser.current, message)
  }

  fn advance() {
    parser.previous = parser.current
    for true {
      parser.current = scanner.scanToken()
      if parser.current.type != TOKEN.ERROR {
        break
      }
      errorAtCurrent(parser.current.lexeme)
    }
  }

  fn consume(type, message) {
    if parser.current.type == type {
      advance()
      return
    }
    errorAtCurrent(message)
  }

  fn consumeIdentifier(message) {
    if parser.current.type == TOKEN.IDENTIFIER {
      advance()
      return
    }
    errorAtCurrent(message)
  }

  fn consumeKey(message) {
    // Accept identifiers and keywords as keys for dot access / hashmap
    if KEY_TOKENS[parser.current.type] {
      advance()
      return
    }
    errorAtCurrent(message)
  }

  fn check(type) { parser.current.type == type }

  fn match(type) {
    if !check(type) { return false }
    advance()
    true
  }

  fn skipSemicolons() {
    for match(TOKEN.SEMICOLON) { }
  }

  fn synchronize() {
    parser.panicMode = false
    for parser.current.type != TOKEN.EOF {
      if SYNC_BREAKPOINTS[parser.current.type] {
        return
      }
      advance()
    }
  }

  fn parsePrecedence(precedence) {
    advance()
    let prefixRule = getRule(parser.previous.type)[0]
    if !prefixRule {
      error("Expect expression.")
      return nil
    }

    let canAssign = precedence <= PREC.ASSIGNMENT
    let left = prefixRule(canAssign)

    for true {
      let rule = getRule(parser.current.type)
      if precedence > rule[2] { break }

      // The rule we just looked up corresponds to the token that `advance()` will
      // move into `parser.previous`.
      advance()
      let infixRule = rule[1]
      if !infixRule {
        error("Expect expression.")
        return nil
      }
      left = infixRule(left, canAssign)
    }

    if canAssign and match(TOKEN.EQUAL) {
      error("Invalid assignment target.")
    }

    return left
  }

  fn literal() {
    let token = parser.previous
    let tokenType = token.type

    if tokenType == TOKEN.FALSE or tokenType == TOKEN.TRUE {
      return BoolNode(filename, token)
    } else if tokenType == TOKEN.NIL {
      return NilNode(filename, token)
    } else {
      error("Unknown literal type.")
      return nil
    }
  }

  fn number() {
    NumberNode(filename, parser.previous)
  }

  fn string() {
    StringNode(filename, parser.previous)
  }

  fn variable(canAssign) {
    let nameToken = parser.previous
    let name = IdentifierNode(filename, nameToken)

    if canAssign and match(TOKEN.EQUAL) {
      let value = expression()
      return AssignmentNode(filename, name, value, parser.previous)
    }

    return name
  }

  fn grouping() {
    let startToken = parser.previous
    let expr = expression()
    consume(TOKEN.RIGHT_PAREN, "Expect ')' after expression.")
    GroupingNode(filename, expr, startToken, parser.previous)
  }

  fn unary() {
    let operator = parser.previous
    let operand = parsePrecedence(PREC.UNARY)
    UnaryNode(filename, operator, operand)
  }

  fn binary(left, canAssign) {
    let operator = parser.previous
    let rule = getRule(operator.type)
    let right = parsePrecedence(rule[2] + 1)
    if !right {
      return left
    }
    BinaryNode(filename, left, operator, right)
  }

  fn and_(left, canAssign) {
    let operator = parser.previous
    // Left-associative: parse RHS at higher precedence
    let right = parsePrecedence(PREC.AND + 1)
    if !right {
      return left
    }
    LogicalNode(filename, left, operator, right)
  }

  fn or_(left, canAssign) {
    let operator = parser.previous
    // Left-associative: parse RHS at higher precedence
    let right = parsePrecedence(PREC.OR + 1)
    if !right {
      return left
    }
    LogicalNode(filename, left, operator, right)
  }

  fn call(left, canAssign) {
    let args = []

    if !check(TOKEN.RIGHT_PAREN) {
      let firstArg = expression()
      if firstArg {
        args = [firstArg]
      }
      for match(TOKEN.COMMA) and !check(TOKEN.RIGHT_PAREN) {
        let arg = expression()
        if arg {
          push(args, arg)
        }
      }
    }

    consume(TOKEN.RIGHT_PAREN, "Expect ')' after arguments.")
    CallNode(filename, left, args, parser.previous)
  }

  fn arrow(left, canAssign) {
    let arrowToken = parser.previous
    // Left-associative: parse RHS at higher precedence
    let right = parsePrecedence(PREC.PIPELINE + 1)
    if !right {
      return left
    }
    ArrowNode(filename, left, right, arrowToken)
  }

  fn dot(left, canAssign) {
    consumeKey("Expect property name after '.'.")
    let propertyToken = parser.previous
    let property = StringKeyNodeFromToken(filename, propertyToken)

    if canAssign and match(TOKEN.EQUAL) {
      let value = expression()
      let dotNode = DotNode(filename, left, property, propertyToken)
      return AssignmentNode(filename, dotNode, value, parser.previous)
    }

    DotNode(filename, left, property, propertyToken)
  }

  fn index(left, canAssign) {
    let indexExpr = expression()
    consume(TOKEN.RIGHT_BRACKET, "Expect ']' for index key.")
    let endToken = parser.previous

    if canAssign and match(TOKEN.EQUAL) {
      let value = expression()
      let indexNode = IndexNode(filename, left, indexExpr, endToken)
      return AssignmentNode(filename, indexNode, value, parser.previous)
    }

    IndexNode(filename, left, indexExpr, endToken)
  }

  fn array() {
    let startToken = parser.previous
    let elements = []

    if !check(TOKEN.RIGHT_BRACKET) {
      let firstElem = expression()
      if firstElem {
        push(elements, firstElem)
      }
      for match(TOKEN.COMMA) and !check(TOKEN.RIGHT_BRACKET) {
        let elem = expression()
        if elem {
          push(elements, elem)
        }
      }
    }

    consume(TOKEN.RIGHT_BRACKET, "Expect ']' after array.")
    ArrayNode(filename, startToken, elements, parser.previous)
  }

  fn enumExpr() {
    let enumToken = parser.previous

    let nextValue = 0
    if match(TOKEN.LEFT_PAREN) {
      consume(TOKEN.NUMBER, "Expect enum start value number.")
      nextValue = int(parser.previous.literal)
      if nextValue != parser.previous.literal {
        errorAt(parser.previous, "Enum start value must be an integer.")
      }
      consume(TOKEN.RIGHT_PAREN, "Expect ')' after enum start value.")
    }

    consume(TOKEN.LEFT_BRACE, "Expect '{' after enum.")

    let pairs = []
    let seen = .{}
    let seenValues = .{}
    let valueToName = .{}

    fn hasNextMember() {
      !check(TOKEN.RIGHT_BRACE) and !check(TOKEN.EOF)
    }

    fn autoNumberNode(value) {
      NumberNode(filename, .{
        lexeme: join([value], ""),
        literal: value,
        line: enumToken.line,
        col: enumToken.col,
      })
    }

    if hasNextMember() {
      fn member() {
        consumeKey("Expect enum member name.")
        let nameToken = parser.previous
        let key = StringKeyNodeFromToken(filename, nameToken)

        if seen[key.value] {
          errorAt(nameToken, "Duplicate enum member: " + key.value)
          return
        }
        seen[key.value] = true

        let valueNode = autoNumberNode(nextValue)
        let valueToken = nameToken

        if match(TOKEN.EQUAL) {
          consume(TOKEN.NUMBER, "Expect enum value number.")
          valueNode = NumberNode(filename, parser.previous)
          valueToken = parser.previous
          nextValue = int(valueNode.value)
          if nextValue != valueNode.value {
            errorAt(valueToken, "Enum value must be an integer.")
            return
          }
        }

        let valueInt = int(valueNode.value)
        if valueInt != valueNode.value {
          // Defensive (auto values are always int).
          errorAt(valueToken, "Enum value must be an integer.")
          return
        }

        let existingName = valueToName[valueInt]
        if existingName {
          errorAt(valueToken,
            "Duplicate enum value: " + join([valueInt], "") + " (already used by " + existingName + ")")
          return
        }

        seenValues[valueInt] = true
        valueToName[valueInt] = key.value

        push(pairs, .{ key: key, value: valueNode })
        nextValue = nextValue + 1
      }

      member()
      for match(TOKEN.COMMA) and hasNextMember() {
        member()
      }
    }

    consume(TOKEN.RIGHT_BRACE, "Expect '}' after enum.")
    let node = HashmapNode(filename, enumToken, pairs, parser.previous)
    parser.enumInfo[node.id] = .{
      members: collect p in pairs { .{ name: p.key.value, value: p.value.value } },
    }
    node
  }

  fn hashmap() {
    let startToken = parser.previous
    let pairs = []

    fn hasNextKeyValuePair() {
      !check(TOKEN.RIGHT_BRACE) and !check(TOKEN.EOF)
    }

    fn syncHashmapPair() {
      // Advance until we hit a comma, closing brace, or EOF
      for !check(TOKEN.COMMA) and !check(TOKEN.RIGHT_BRACE) and !check(TOKEN.EOF) {
        advance()
      }
    }

    if hasNextKeyValuePair() {
      fn keyvalue() {
        let key
        let keyIdentToken = nil
        if match(TOKEN.LEFT_BRACKET) {
          // index pattern `.{ [expr]: value }`
          key = expression()
          if !key {
            syncHashmapPair()  // Recover to comma/brace boundary
            return
          }
          consume(TOKEN.RIGHT_BRACKET, "Expect ']' for hashmap index key.")
        } else {
          // key pattern `.{ key: value }` or shorthand `.{ key }`
          if parser.current.type == TOKEN.IDENTIFIER {
            advance()
            keyIdentToken = parser.previous
            key = StringKeyNodeFromToken(filename, keyIdentToken)
          } else {
            // Accept keywords as explicit keys (must use `:` form).
            consumeKey("Expect key for hashmap.")
            key = StringKeyNodeFromToken(filename, parser.previous)
          }
        }

        // Shorthand: `.{ x, y }` expands to `.{ x: x, y: y }`.
        // Only supported for identifiers (keywords require explicit `:`).
        if keyIdentToken and !check(TOKEN.COLON) {
          push(pairs, .{ key: key, value: IdentifierNode(filename, keyIdentToken) })
          return
        }

        consume(TOKEN.COLON, "Expect ':' for hashmap.")

        let value = expression()
        if value {
          push(pairs, .{ key: key, value: value })
        }
      }

      keyvalue()
      for match(TOKEN.COMMA) and hasNextKeyValuePair() {
        keyvalue()
      }
    }

    consume(TOKEN.RIGHT_BRACE, "Expect '}' after hashmap.")
    HashmapNode(filename, startToken, pairs, parser.previous)
  }

  fn block() {
    let startToken = parser.previous
    let expressions = []

    fn hasNextExpression() {
      !check(TOKEN.RIGHT_BRACE) and !check(TOKEN.EOF)
    }

    for hasNextExpression() {
      skipSemicolons()  // Skip any leading semicolons
      if !hasNextExpression() { break }  // Re-check after skipping

      let expr = expression()

      // Only push non-nil expressions (error recovery)
      if expr {
        push(expressions, expr)
      }
    }

    consume(TOKEN.RIGHT_BRACE, "Expect '}' after block.")
    BlockNode(filename, startToken, expressions, parser.previous)
  }

  fn letExpr() {
    let startToken = parser.previous
    if match(TOKEN.DOT_BRACE) {
      // Destructuring let:
      //   let .{ OP, NODE } = expr
      //   let .{ OP: op, NODE: node } = expr
      let bindings = []

      fn hasNextBinding() {
        !check(TOKEN.RIGHT_BRACE) and !check(TOKEN.EOF)
      }

      if hasNextBinding() {
        fn binding() {
          consumeIdentifier("Expect identifier in destructuring pattern.")
          let keyToken = parser.previous
          let key = StringKeyNodeFromToken(filename, keyToken)

          let name = IdentifierNode(filename, keyToken)
          if match(TOKEN.COLON) {
            consumeIdentifier("Expect binding name after ':'.")
            name = IdentifierNode(filename, parser.previous)
          }

          push(bindings, .{ key: key, name: name })
        }

        binding()
        for match(TOKEN.COMMA) and hasNextBinding() {
          binding()
        }
      }

      consume(TOKEN.RIGHT_BRACE, "Expect '}' after destructuring pattern.")

      consume(TOKEN.EQUAL, "Expect '=' after destructuring pattern.")
      let init = expression()

      if init and init.type == NODE.Let {
        error("'let' cannot be used directly as an initializer (use a block: { let y = ...; y })")
      }

      return LetDestructureNode(filename, startToken, bindings, init)
    }

    consumeIdentifier("Expect variable name.")
    let nameToken = parser.previous

    let init = nil
    if match(TOKEN.EQUAL) {
      init = expression()
      // Disallow "let in let" pattern: let x = let y = ...
      if init and init.type == NODE.Let {
        error("'let' cannot be used directly as an initializer (use a block: { let y = ...; y })")
      }
    }

    LetNode(filename, startToken, nameToken, init)
  }

  fn fnExpr() {
    let startToken = parser.previous
    let name = nil

    if check(TOKEN.IDENTIFIER) {
      advance()
      name = IdentifierNode(filename, parser.previous)
    }

    consume(TOKEN.LEFT_PAREN, "Expect '(' after function name.")

    let params = []
    if !check(TOKEN.RIGHT_PAREN) {
      consumeIdentifier("Expect parameter name.")
      push(params, IdentifierNode(filename, parser.previous))

      for match(TOKEN.COMMA) and !check(TOKEN.RIGHT_PAREN) {
        consumeIdentifier("Expect parameter name.")
        push(params, IdentifierNode(filename, parser.previous))
      }
    }

    consume(TOKEN.RIGHT_PAREN, "Expect ')' after parameters.")
    consume(TOKEN.LEFT_BRACE, "Expect '{' before function body.")

    let body = block()

    FunctionNode(filename, startToken, name, params, body, parser.previous)
  }

  fn ifExpr() {
    let startToken = parser.previous
    let condition = expression()

    consume(TOKEN.LEFT_BRACE, "Expect '{' after condition.")
    let thenBranch = block()

    let elseBranch = nil
    if match(TOKEN.ELSE) {
      if match(TOKEN.IF) {
        elseBranch = ifExpr()
      } else {
        consume(TOKEN.LEFT_BRACE, "Expect '{' after else.")
        elseBranch = block()
      }
    }

    IfNode(filename, startToken, condition, thenBranch, elseBranch)
  }

  fn forExpr() {
    let startToken = parser.previous

    // Check for for-in syntax: for x in arr { } or for x, i in arr { }
    // We need to lookahead to detect this pattern
    let isForIn = false
    if check(TOKEN.IDENTIFIER) {
      // Peek ahead to see if this is for-in
      // peek(0) gives the next token to be consumed (after current)
      let nextToken = scanner.peek(0)
      if nextToken.type == TOKEN.IN or nextToken.type == TOKEN.COMMA {
        isForIn = true
      }
    }

    if isForIn {
      // Parse for-in loop
      consume(TOKEN.IDENTIFIER, "Expect identifier in for-in loop.")
      let valueBinder = parser.previous.lexeme

      let indexBinder = nil
      if match(TOKEN.COMMA) {
        consume(TOKEN.IDENTIFIER, "Expect identifier after comma in for-in loop.")
        indexBinder = parser.previous.lexeme
      }

      consume(TOKEN.IN, "Expect 'in' in for-in loop.")
      let iterable = expression()

      consume(TOKEN.LEFT_BRACE, "Expect '{' for block.")
      let body = block()

      return ForInNode(filename, startToken, valueBinder, indexBinder, iterable, body, parser.previous)
    }

    // Original for loop logic
    let init = nil
    let condition = nil
    let update = nil
    let isCStyle = false

    if match(TOKEN.SEMICOLON) {
      // for ;; style - no init but C-style
      isCStyle = true
    } else {
      let expr = expression()
      if match(TOKEN.SEMICOLON) {
        // for init; style - C-style
        init = expr
        isCStyle = true
      } else {
        // for condition {} style (while loop)
        condition = expr
      }
    }

    // Parse condition if we're in C-style for loop
    if isCStyle and !check(TOKEN.LEFT_BRACE) {
      if !match(TOKEN.SEMICOLON) {
        condition = expression()
        consume(TOKEN.SEMICOLON, "Expect ';' after loop condition.")
      }
    }

    // Parse update if present in C-style loop
    if isCStyle and !check(TOKEN.LEFT_BRACE) {
      update = expression()
    }

    consume(TOKEN.LEFT_BRACE, "Expect '{' for block.")
    let body = block()

    ForNode(filename, startToken, init, condition, update, body, parser.previous)
  }

  fn collectExpr() {
    let startToken = parser.previous

    // Check for collect-in syntax: collect x in arr { } or collect x, i in arr { }
    let isCollectIn = false
    if check(TOKEN.IDENTIFIER) {
      let nextToken = scanner.peek(0)
      if nextToken.type == TOKEN.IN or nextToken.type == TOKEN.COMMA {
        isCollectIn = true
      }
    }

    if isCollectIn {
      // Parse collect-in loop
      consume(TOKEN.IDENTIFIER, "Expect identifier in collect-in loop.")
      let valueBinder = parser.previous.lexeme

      let indexBinder = nil
      if match(TOKEN.COMMA) {
        consume(TOKEN.IDENTIFIER, "Expect identifier after comma in collect-in loop.")
        indexBinder = parser.previous.lexeme
      }

      consume(TOKEN.IN, "Expect 'in' in collect-in loop.")
      let iterable = expression()

      consume(TOKEN.LEFT_BRACE, "Expect '{' for block.")
      let body = block()

      return CollectInNode(filename, startToken, valueBinder, indexBinder, iterable, body, parser.previous)
    }

    // Parse collect loop (C-style or while-style)
    let init = nil
    let condition = nil
    let update = nil
    let isCStyle = false

    if match(TOKEN.SEMICOLON) {
      isCStyle = true
    } else {
      let expr = expression()
      if match(TOKEN.SEMICOLON) {
        init = expr
        isCStyle = true
      } else {
        condition = expr
      }
    }

    if isCStyle and !check(TOKEN.LEFT_BRACE) {
      if !match(TOKEN.SEMICOLON) {
        condition = expression()
        consume(TOKEN.SEMICOLON, "Expect ';' after loop condition.")
      }
    }

    if isCStyle and !check(TOKEN.LEFT_BRACE) {
      update = expression()
    }

    consume(TOKEN.LEFT_BRACE, "Expect '{' for block.")
    let body = block()

    CollectNode(filename, startToken, init, condition, update, body, parser.previous)
  }

  fn returnStatement() {
    let startToken = parser.previous

    let value = nil
    if !check(TOKEN.RIGHT_BRACE) and !check(TOKEN.EOF) {
      value = expression()
    }

    ReturnNode(filename, startToken, value)
  }

  fn breakStmt() {
    BreakNode(filename, parser.previous)
  }

  fn continueStmt() {
    ContinueNode(filename, parser.previous)
  }

  fn importStatement() {
    let startToken = parser.previous
    consume(TOKEN.STRING, "Import path should be a string.")
    let pathNode = StringNode(filename, parser.previous)
    ImportNode(filename, startToken, pathNode)
  }

  fn expression() {
    if match(TOKEN.IMPORT) {
      return importStatement()
    }
    parsePrecedence(PREC.ASSIGNMENT)
  }

  fn expressionStatement() {
    let expr = expression()
    if parser.panicMode {
      synchronize()
    }
    return expr
  }

  // Parse rules table
  let parseRules = .{
    [TOKEN.IMPORT]:          [nil,        nil,    PREC.NONE],
    [TOKEN.LEFT_PAREN]:      [grouping,   call,   PREC.CALL],
    [TOKEN.RIGHT_PAREN]:     [nil,        nil,    PREC.NONE],
    [TOKEN.LEFT_BRACE]:      [block,      nil,    PREC.NONE],
    [TOKEN.RIGHT_BRACE]:     [nil,        nil,    PREC.NONE],
    [TOKEN.LEFT_BRACKET]:    [array,      index,  PREC.CALL],
    [TOKEN.RIGHT_BRACKET]:   [nil,        nil,    PREC.NONE],
    [TOKEN.DOT_BRACE]:       [hashmap,    nil,    PREC.NONE],
    [TOKEN.COMMA]:           [nil,        nil,    PREC.NONE],
    [TOKEN.DOT]:             [nil,        dot,    PREC.CALL],
    [TOKEN.MINUS]:           [unary,      binary, PREC.TERM],
    [TOKEN.MINUS_GREATER]:   [nil,        arrow,  PREC.PIPELINE],
    [TOKEN.PLUS]:            [nil,        binary, PREC.TERM],
    [TOKEN.SEMICOLON]:       [nil,        nil,    PREC.NONE],
    [TOKEN.SLASH]:           [nil,        binary, PREC.FACTOR],
    [TOKEN.STAR]:            [nil,        binary, PREC.FACTOR],
    [TOKEN.MOD]:             [nil,        binary, PREC.FACTOR],
    [TOKEN.BANG]:            [unary,      nil,    PREC.UNARY],
    [TOKEN.BANG_EQUAL]:      [nil,        binary, PREC.EQUALITY],
    [TOKEN.EQUAL]:           [nil,        nil,    PREC.NONE],
    [TOKEN.EQUAL_EQUAL]:     [nil,        binary, PREC.EQUALITY],
    [TOKEN.GREATER]:         [nil,        binary, PREC.COMPARISON],
    [TOKEN.GREATER_EQUAL]:   [nil,        binary, PREC.COMPARISON],
    [TOKEN.GREATER_GREATER]: [nil,        binary, PREC.BIT_SHIFT],
    [TOKEN.LESS]:            [nil,        binary, PREC.COMPARISON],
    [TOKEN.LESS_EQUAL]:      [nil,        binary, PREC.COMPARISON],
    [TOKEN.LESS_LESS]:       [nil,        binary, PREC.BIT_SHIFT],
    [TOKEN.AMPERSAND]:       [nil,        binary, PREC.BIT_AND],
    [TOKEN.PIPE]:            [nil,        binary, PREC.BIT_OR],
    [TOKEN.CARET]:           [nil,        binary, PREC.BIT_XOR],
    [TOKEN.LET]:             [letExpr,    nil,    PREC.NONE],
    [TOKEN.ENUM]:            [enumExpr,   nil,    PREC.NONE],
    [TOKEN.IDENTIFIER]:      [variable,   nil,    PREC.NONE],
    [TOKEN.STRING]:          [string,     nil,    PREC.NONE],
    [TOKEN.NUMBER]:          [number,     nil,    PREC.NONE],
    [TOKEN.AND]:             [nil,        and_,   PREC.AND],
    [TOKEN.ELSE]:            [nil,        nil,    PREC.NONE],
    [TOKEN.FALSE]:           [literal,    nil,    PREC.NONE],
    [TOKEN.FOR]:             [forExpr,    nil,    PREC.NONE],
    [TOKEN.FN]:              [fnExpr,     nil,    PREC.NONE],
    [TOKEN.IF]:              [ifExpr,     nil,    PREC.NONE],
    [TOKEN.NIL]:             [literal,    nil,    PREC.NONE],
    [TOKEN.OR]:              [nil,        or_,    PREC.OR],
    [TOKEN.RETURN]:          [returnStatement, nil, PREC.NONE],
    [TOKEN.BREAK]:           [breakStmt,  nil,    PREC.NONE],
    [TOKEN.CONTINUE]:        [continueStmt, nil,  PREC.NONE],
    [TOKEN.TRUE]:            [literal,    nil,    PREC.NONE],
    [TOKEN.IN]:              [nil,        nil,    PREC.NONE],
    [TOKEN.COLLECT]:         [collectExpr, nil,   PREC.NONE],
    [TOKEN.ERROR]:           [nil,        nil,    PREC.NONE],
    [TOKEN.EOF]:             [nil,        nil,    PREC.NONE],
  }

  let DEFAULT_RULE = [nil, nil, PREC.NONE]

  fn getRule(type) {
    parseRules[type] or DEFAULT_RULE
  }

  // Main parsing loop
  advance()
  let body = collect !match(TOKEN.EOF) {
    skipSemicolons()  // Skip any leading semicolons
    if check(TOKEN.EOF) { break }  // Re-check after skipping

    expressionStatement() or { continue }
  }

  // Root is an implicit block (no braces). Range spans the full file.
  let rootStartToken = .{ lexeme: "", line: 1, col: 0 }
  let root = BlockNode(filename, rootStartToken, body, parser.previous)

  return .{
    success: !parser.hadError,
    ast: root,
    errors: parser.errors,
    enumInfo: parser.enumInfo,
    nextNodeId: nodeIdCounter + 1,
  }
}
