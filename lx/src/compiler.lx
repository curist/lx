let lib = import "src/lib.lx"
let types = import "src/types.lx"
let initScanner = import "src/scanner.lx"
let object = import "src/object.lx"

// let globals = import "globals.lx"
// let each = globals.each

let TOKEN = types.TOKEN
let OP = types.OP
let ValueType = types.ValueType
let ObjType = object.ObjType

let UINT16_MAX = 256 * 256

let importCache = .{}

let PREC = {
  let iota = lib.iota(0)
  .{
    NONE:       iota(),
    ASSIGNMENT: iota(),  // =
    OR:         iota(),  // or
    AND:        iota(),  // and
    BIT_OR:     iota(),  // |
    BIT_XOR:    iota(),  // ^
    BIT_AND:    iota(),  // &
    EQUALITY:   iota(),  // == !=
    COMPARISON: iota(),  // < > <= >=
    BIT_SHIFT:  iota(),  // << >>
    TERM:       iota(),  // + -
    FACTOR:     iota(),  // * /
    UNARY:      iota(),  // ! -
    CALL:       iota(),  // . ()
    PRIMARY:    iota(),
  }
}

let FunctionType = {
  let iota = lib.iota(0)
  .{
    FUNCTION: iota(),
    SCRIPT:   iota(),
  }
}

fn Value(kind, value) {.{
  kind: kind,
  value: value,
}}

fn Chunk(filename) {.{
  filename: filename,
  bytecode: [],
  constants: [],
  lines: [],
  constantsCache: .{},
  importConstCache: .{},
}}

fn Function(name, type, arity, chunk) {.{
  name: name,
  type: type,
  arity: arity,
  chunk: chunk,
  upvalueCount: 0,
}}


fn Local(name, depth) {.{
  name: name,
  depth: depth,
  isCaptured: false,
}}

fn Upvalue(index, isLocal) {.{
  index: index,
  isLocal: isLocal,
}}

fn Compiler(type) {.{
  enclosing: nil,
  locals: [],
  upvalues: .{},
  scopeDepth: 0,
  function: nil,
  type: type,
}}

fn BOOL_VAL(value)   { Value(ValueType.BOOL, value) }
fn NIL_VAL(value)    { Value(ValueType.NIL, nil) }
// XXX: ^ not sure if we need these two
fn NUMBER_VAL(value) { Value(ValueType.NUMBER, value) }
fn OBJ_VAL(value)    { Value(ValueType.OBJ, value) }

fn ObjectFunction(func) { OBJ_VAL(object.ObjectFunction(func)) }
fn ObjectString(string) { OBJ_VAL(object.ObjectString(string)) }

let pp = lib.pp

fn purifyFunction(func) {.{
  name: func.name,
  arity: func.arity,
  upvalueCount: func.upvalueCount,
  chunk: .{
    filename: func.chunk.filename,
    bytecode: func.chunk.bytecode,
    constants: func.chunk.constants,
    lines: func.chunk.lines,
  },
}}

fn compile(src, filename, opts) {
  let scanner = initScanner(src)

  let isModule = !opts.main

  // to get around mutual references
  let parseRules
  let getRule

  let parser = .{
    current: 0,
    previous: 0,
    hadError: false,
    panicMode: false,
  }

  let loopScopeDepth = 0
  let breakOffsets = []
  let continueOffsets = []

  let pendingCallCount = 0

  let current
  fn initCompiler(type, filename) {
    let compiler = Compiler(type)
    compiler.enclosing = current
    compiler.function = Function("", type, 0, Chunk(filename))
    compiler.locals = [Local("", 0)]
    current = compiler

    if type != FunctionType.SCRIPT {
      current.function.name = parser.previous.lexeme
    }
    return compiler
  }
  initCompiler(FunctionType.SCRIPT, filename)

  fn currentChunk() {
    current.function.chunk
  }

  fn errorAt(token, message) {
    if parser.panicMode {
      return
    }
    parser.panicMode = true
    pp([
      "[", filename, ":L", token.line, "]",
      if token.type == TOKEN.EOF {
        " at end"
      } else if token.type == TOKEN.ERROR {
        ""
      } else {
        " at '" + token.lexeme + "'"
      },
      ": ", message,
    ])
    parser.hadError = true
  }

  fn error(message) {
    errorAt(parser.previous, message)
  }

  fn errorAtCurrent(message) {
    errorAt(parser.current, message)
  }

  fn emitByte(byte, line) {
    let chunk = currentChunk()
    push(chunk.bytecode, lib.tohex(byte))
    push(chunk.lines, line)
  }

  fn emitBytes(byte1, byte2, line) {
    emitByte(byte1, line)
    emitByte(byte2, line)
  }

  fn emitLoop(loopStart, line) {
    emitByte(OP.LOOP, line)

    let offset = len(currentChunk().bytecode) - loopStart + 2
    if offset > UINT16_MAX {
      error("Loop body too large.")
    }

    emitByte(int(offset / 256), line)
    emitByte(offset % 256, line)
  }

  fn emitJump(instruction) {
    let line = parser.previous.line
    emitByte(instruction, line)
    emitBytes(255, 255, line)
    return len(currentChunk().bytecode) - 2
  }

  fn calcValueKey(value) {
    let k = str(value.kind) + ":"
    if value.kind == ValueType.NUMBER {
      k = k + str(value.value)
    } else if value.kind == ValueType.OBJ {
      let obj = value.value
      k = k + str(obj.kind) + ":"
      if obj.kind == ObjType.STRING {
        k = k + obj.value
      } else {
        return "nocache"
      }

    } else {
      // currently only BOOL & NIL is in the category
      // and...they won't be stored in constants
      error("Invalid to calculate cache key for constant.")
    }
    return k
  }

  fn addConstant(chunk, value) {
    let k = calcValueKey(value)
    if k == "nocache" {
      push(chunk.constants, value)
      return len(chunk.constants) - 1
    }
    let index = chunk.constantsCache[k]
    if index { return index }
    push(chunk.constants, value)
    index = len(chunk.constants) - 1
    chunk.constantsCache[k] = index
    return index
  }

  fn makeConstant(value) {
    let constant = addConstant(currentChunk(), value)
    if constant > 256 {
      error("Too many constants in one chunk.")
      return 0
    }
    return constant
  }

  fn emitConstant(value, line) {
    emitBytes(OP.CONSTANT, makeConstant(value), line)
  }

  fn patchJump(offset) {
    let jump = len(currentChunk().bytecode) - offset - 2

    if jump > UINT16_MAX {
      error("Too much code to jump over.")
    }
    currentChunk().bytecode[offset] = lib.tohex(int(jump / 256))
    currentChunk().bytecode[offset + 1] = lib.tohex(jump % 256)
  }

  fn advance() {
    parser.previous = parser.current
    for true {
      parser.current = scanner.scanToken()
      if parser.current.type != TOKEN.ERROR {
        break
      }
      errorAtCurrent(parser.current.lexeme)
    }
  }

  fn consume(type, message) {
    if parser.current.type == type {
      advance()
      return
    }
    errorAtCurrent(message)
  }

  fn check(type) { parser.current.type == type }

  fn match(type) {
    if !check(type) {return false}
    advance()
    true
  }

  fn emitReturn() {
    emitByte(OP.RETURN, parser.previous.line)
  }

  fn parsePrecedence(precedence) {
    advance()
    let prefixRule = getRule(parser.previous.type).prefix
    if !prefixRule {
      error("Expect expression.")
      return
    }

    let canAssign = precedence <= PREC.ASSIGNMENT
    prefixRule(canAssign)

    for precedence <= getRule(parser.current.type).precedence {
      advance()
      let infixRule = getRule(parser.previous.type).infix
      // XXX: should we really error out here?
      if !infixRule {
        error("Expect expression.")
        return
      }
      infixRule(canAssign)
    }

    if canAssign and match(TOKEN.EQUAL) {
      error("Invalid assignment target.")
    }
  }

  fn identifierConstant(name) {
    makeConstant(ObjectString(name))
  }

  fn identifiersEqual(nameA, nameB) { nameA == nameB }

  fn lowerResolvedLocal(compiler, index) {
    for let i = index - 1; i >= 1; i = i - 1 {
      let local = compiler.locals[i]
      if local.depth == -1 { index = index - 1 }
    }
    index
  }

  fn resolveLocal(compiler, name) {
    // we were assuming all variables before latest one are initialized,
    // but that's not true for our case; in a scenario like
    // let x = { let foo }
    // `foo` gets initialized before `x` does
    // when we get an index, we must also subtract
    // how many unintialized variables are before our variable
    for let i = len(compiler.locals) - 1; i >= 1; i = i - 1 {
      let local = compiler.locals[i]
      if identifiersEqual(name, local.name) {
        // keep finding
        if local.depth == -1 {
          error("Can't read local variable in its own initializer.")
        }
        return lowerResolvedLocal(compiler, i)
      }
    }
    return -1
  }

  fn addUpvalue(compiler, index, isLocal) {
    let upvalueCount = compiler.function.upvalueCount

    for let i = 0; i < upvalueCount; i = i + 1 {
      let upvalue = compiler.upvalues[i]
      if upvalue.index == index and upvalue.isLocal == isLocal {
        return i
      }
    }

    if upvalueCount == 256 {
      error("Too many closure variables in function.")
      return 0
    }

    compiler.upvalues[upvalueCount] = Upvalue(index, isLocal)
    compiler.function.upvalueCount = upvalueCount + 1
    return upvalueCount
  }

  fn resolveUpvalue(compiler, name) {
    if !compiler.enclosing { return -1 }

    let local = resolveLocal(compiler.enclosing, name)

    if local != -1 {
      compiler.enclosing.locals[local].isCaptured = true
      return addUpvalue(compiler, local, true)
    }

    let upvalue = resolveUpvalue(compiler.enclosing, name)
    if upvalue != -1 {
      return addUpvalue(compiler, upvalue, false)
    }

    return -1
  }

  fn addLocal(name) {
    if len(current.locals) >= 256 {
      error("Too many local variables in function.")
      return
    }
    if name == "_" { name = "" }
    push(current.locals, Local(name, -1))
  }

  fn reserveLocal() {
    if len(current.locals) >= 256 {
      error("Too many local variables in function.")
      return
    }
    push(current.locals, Local("", current.scopeDepth))
    emitByte(OP.NIL, parser.previous.line)
    emitByte(OP.NEW_LOCAL, parser.previous.line)
    return lowerResolvedLocal(current, len(current.locals) - 1)
  }

  fn declareVariable() {
    if current.scopeDepth == 0 {
      return
    }

    let name = parser.previous.lexeme

    for let i = len(current.locals) - 1; i >= 0; i = i - 1 {
      let local = current.locals[i]
      if local.depth != -1 and local.depth < current.scopeDepth {
        break
      }

      if identifiersEqual(name, local.name) {
        error("Already a variable with this name in this scope.")
      }
    }

    addLocal(name)
  }

  fn parseVariable(errorMessage) {
    consume(TOKEN.IDENTIFIER, errorMessage)

    declareVariable()
    if current.scopeDepth > 0 {
      return 0
    }
    identifierConstant(parser.previous.lexeme)
  }

  fn markInitialized() {
    if current.scopeDepth == 0 {
      return
    }
    current.locals[len(current.locals) - 1].depth = current.scopeDepth
  }

  fn defineVariable(global, isArg, line) {
    if current.scopeDepth > 0 {
      markInitialized()
      if !isArg {
        emitByte(OP.NEW_LOCAL, line)
      }
      return
    }
    emitBytes(OP.DEFINE_GLOBAL, global, line)
  }

  fn and_() {
    emitByte(OP.DUP, parser.previous.line)
    let endJump = emitJump(OP.JUMP_IF_FALSE)
    emitByte(OP.POP, parser.previous.line)
    parsePrecedence(PREC.AND)
    patchJump(endJump)
  }

  fn endCompiler() {
    emitReturn()
    let func = current.function
    current = current.enclosing
    return purifyFunction(func)
  }

  fn beginScope() {
    current.scopeDepth = current.scopeDepth + 1
  }

  fn endScope() {
    current.scopeDepth = current.scopeDepth - 1

    fn shouldPop() {
      len(current.locals) > 0 and
        current.locals[len(current.locals) - 1].depth > current.scopeDepth
    }

    let line = parser.previous.line

    for shouldPop() {
      // XXX: CLOSE_UPVALUE mixes with POP_LOCAL
      if current.locals[len(current.locals) - 1].isCaptured {
        emitByte(OP.CLOSE_UPVALUE, line)
      } else {
        emitByte(OP.POP_LOCAL, line)
      }
      pop(current.locals)
    }

    // XXX: warn on unused local variables (shall we?)
  }

  fn resetScopeVariables(n) {
    let localIndex = len(current.locals) - 1

    fn shouldPop() {
      localIndex >= 0 and current.locals[localIndex].depth > n
    }

    let totalPops = 0
    for shouldPop() {
      totalPops = totalPops + 1
      localIndex = localIndex - 1
      emitByte(OP.POP_LOCAL, parser.previous.line)
    }
  }

  fn binary() {
    let operatorType = parser.previous.type
    let line = parser.previous.line
    let rule = getRule(operatorType)
    parsePrecedence(rule.precedence + 1)

    let opCodes = .{
      [TOKEN.BANG_EQUAL]:      [OP.EQUAL, OP.NOT],
      [TOKEN.EQUAL_EQUAL]:      OP.EQUAL,
      [TOKEN.GREATER]:          OP.GREATER,
      [TOKEN.GREATER_EQUAL]:   [OP.LESS, OP.NOT],
      [TOKEN.GREATER_GREATER]:  OP.BIT_RSHIFT,
      [TOKEN.LESS]:             OP.LESS,
      [TOKEN.LESS_EQUAL]:      [OP.GREATER, OP.NOT],
      [TOKEN.LESS_LESS]:        OP.BIT_LSHIFT,
      [TOKEN.PLUS]:             OP.ADD,
      [TOKEN.MINUS]:            OP.SUBTRACT,
      [TOKEN.STAR]:             OP.MULTIPLY,
      [TOKEN.SLASH]:            OP.DIVIDE,
      [TOKEN.MOD]:              OP.MOD,
      [TOKEN.AMPERSAND]:        OP.BIT_AND,
      [TOKEN.PIPE]:             OP.BIT_OR,
      [TOKEN.CARET]:            OP.BIT_XOR,
    }
    let codes = opCodes[operatorType]
    if codes {
      if type(codes) == "array" {
        emitBytes(codes[0], codes[1], line)
      } else {
        emitByte(codes, line)
      }
    } else {
      // unreachable, supposely
      error("bad binary op: " + types.TOKEN_NAME[operatorType])
    }
  }

  fn literal() {
    let operatorType = parser.previous.type

    let opCodes = .{
      [TOKEN.FALSE]: OP.FALSE,
      [TOKEN.NIL]: OP.NIL,
      [TOKEN.TRUE]: OP.TRUE,
    }
    let opCode = opCodes[operatorType]
    if opCode {
      emitByte(opCode, parser.previous.line)
    } else {
      // unreachable, supposely
      error("bad literal op: " + types.TOKEN_NAME[operatorType])
    }
  }

  fn importStatment() {
    // TODO: handle relative path
    consume(TOKEN.STRING, "Import path should be a string.")
    let path = parser.previous.literal

    let current = currentChunk()
    let const = current.importConstCache[path]
    if !const {
      let func = importCache[path]
      if !func {
        let realPath = {
          if path[0] != "@" {
            path
          } else {
            let s = "~/lx/"
            let length = len(path)
            for let i = 1; i < length; i = i + 1 {
              s = s + path[i]
            }
            s
          }
        }
        let src = slurp(realPath)
        if !src {
          error("Fail to import: " + path)
          return
        }
        let result = compile(src, path, .{})
        func = result.function
        importCache[path] = func
      }
      const = makeConstant(ObjectFunction(func))
      current.importConstCache[path] = const
    }

    let line = parser.previous.line
    emitBytes(OP.CLOSURE, const, line)
    emitBytes(OP.CALL, 0, line)
  }

  fn expression() {
    if (match(TOKEN.IMPORT)) {
      return importStatment()
    }
    parsePrecedence(PREC.ASSIGNMENT)
  }

  fn argumentList() {
    let argCount = pendingCallCount

    if pendingCallCount > 0 {
      emitByte(OP.SWAP, parser.previous.line)
      pendingCallCount = pendingCallCount - 1
    }

    fn parseArg() {
      expression()
      if (argCount == 255) {
        error("Can't have more than 255 arguments.")
      }
      argCount = argCount + 1
    }
    if !check(TOKEN.RIGHT_PAREN) {
      parseArg()
      for match(TOKEN.COMMA) and !check(TOKEN.RIGHT_PAREN) {
        parseArg()
      }
    }
    consume(TOKEN.RIGHT_PAREN, "Expect ')' after arguments.")
    return argCount
  }

  fn call() {
    let line = parser.previous.line
    let argCount = argumentList()
    emitBytes(OP.CALL, argCount, line)
  }

  fn dot(canAssign) {
    consume(TOKEN.IDENTIFIER, "Expect property name after '.'.")
    emitConstant(ObjectString(parser.previous.lexeme), parser.previous.line)

    if canAssign and match(TOKEN.EQUAL) {
      expression()
      emitByte(OP.SET_BY_INDEX, parser.previous.line)
    } else {
      emitByte(OP.GET_BY_INDEX, parser.previous.line)
    }
  }

  fn arrow() {
    pendingCallCount = pendingCallCount + 1
    expression()
  }

  fn index(canAssign) {
    // index key
    expression()
    consume(TOKEN.RIGHT_BRACKET, "Expect ']' for index key.")

    if canAssign and match(TOKEN.EQUAL) {
      // value
      expression()
      emitByte(OP.SET_BY_INDEX, parser.previous.line)
    } else {
      emitByte(OP.GET_BY_INDEX, parser.previous.line)
    }
  }

  fn synchronize() {
    parser.panicMode = false
    for parser.current.type != TOKEN.EOF {
      let breakpoints = .{
        [TOKEN.FN]: true,
        [TOKEN.LET]: true,
        [TOKEN.FOR]: true,
        [TOKEN.IF]: true,
        [TOKEN.RETURN]: true,
        [TOKEN.IMPORT]: true,
        [TOKEN.DOT_BRACE]: true,
      }
      if breakpoints[parser.current.type] {
        return
      }
      advance()
    }
  }

  fn returnStatement() {
    if check(TOKEN.RIGHT_BRACE) {
      emitByte(OP.NIL, parser.previous.line)
      emitReturn()
      return
    }
    expression()

    if current.type == FunctionType.SCRIPT {
      if !check(TOKEN.EOF) {
        error("Can only return at end of file.")
      }
    } else if !check(TOKEN.RIGHT_BRACE) {
      error("Can only return at end of block.")
    }
    emitByte(OP.RETURN, parser.previous.line)
  }

  fn expressionStatement() {
    let line = parser.current.line

    expression()

    if parser.panicMode {
      synchronize()
    } else if !check(TOKEN.EOF) {
      emitByte(OP.POP, line)
    }
  }

  fn block() {
    let hasExpression = false
    fn hasNextExpression() {
      !check(TOKEN.RIGHT_BRACE) and !check(TOKEN.EOF)
    }
    for hasNextExpression() {
      hasExpression = true
      let line = parser.current.line
      expression()

      // don't pop last evaluated expression
      // so we check ahead if we are going to run another loop
      if hasNextExpression() {
        emitByte(OP.POP, line)
      }
    }

    if !hasExpression {
      emitByte(OP.NIL, parser.previous.line)
    }

    consume(TOKEN.RIGHT_BRACE, "Expect '}' after block.")
  }

  fn blocker() {
    beginScope()
    block()
    endScope()
  }

  fn function(functionType) {
    let line = parser.previous.line
    let compiler = initCompiler(functionType, filename)
    beginScope()
    consume(TOKEN.LEFT_PAREN, "Expect '(' after function name.")
    if !check(TOKEN.RIGHT_PAREN) {
      fn parameter() {
        current.function.arity = current.function.arity + 1
        if current.function.arity > 255 {
          errorAtCurrent("Can't have more than 255 parameters.")
        }
        let constant = parseVariable("Expect parameter name.")
        defineVariable(constant, true, parser.previous.line)
      }

      parameter()
      for match(TOKEN.COMMA) and !check(TOKEN.RIGHT_PAREN) {
        parameter()
      }
    }
    consume(TOKEN.RIGHT_PAREN, "Expect ')' after parameters.")
    consume(TOKEN.LEFT_BRACE, "Expect '{' before function body.")
    block()

    let func = endCompiler()
    let function = purifyFunction(func)
    emitBytes(OP.CLOSURE, makeConstant(ObjectFunction(function)), line)

    for let i = 0; i < func.upvalueCount; i = i + 1 {
      emitByte(if compiler.upvalues[i].isLocal { 1 } else 0, line)
      emitByte(compiler.upvalues[i].index, line)
    }
  }

  fn fnExpr() {
    if check(TOKEN.LEFT_PAREN) {
      // anonymous function
      function(FunctionType.FUNCTION)
      return
    }
    let global = parseVariable("Expect function name.")
    markInitialized()
    function(FunctionType.FUNCTION)
    emitByte(OP.DUP, parser.previous.line)
    defineVariable(global, false, parser.previous.line)
  }

  fn ifExpr() {
    expression()

    consume(TOKEN.LEFT_BRACE, "Expect '{' after condition.")

    let thenJump = emitJump(OP.JUMP_IF_FALSE)
    blocker()

    let elseJump = emitJump(OP.JUMP)

    patchJump(thenJump)

    if match(TOKEN.ELSE) {
      expression()
    } else {
      emitByte(OP.NIL, parser.previous.line)
    }
    patchJump(elseJump)
  }

  fn letExpr() {
    let line = parser.current.line
    let global = parseVariable("Expect variable name.")
    if match(TOKEN.EQUAL) {
      expression()
    } else {
      emitByte(OP.NIL, line)
    }
    emitByte(OP.DUP, line)

    defineVariable(global, false, line)
  }

  fn grouping() {
    expression()
    consume(TOKEN.RIGHT_PAREN, "Expect ')' after expression.")
  }

  fn hashmap() {
    emitByte(OP.HASHMAP, parser.previous.line)

    fn hasNextKeyValuePair() {
      !check(TOKEN.RIGHT_BRACE) and !check(TOKEN.EOF)
    }
    fn keyvalue() {
      if match(TOKEN.LEFT_BRACKET) {
        // index pattern `.{ [expr]: value }`
        expression()
        consume(TOKEN.RIGHT_BRACKET, "Expect ']' for hashmap index key.")
      } else {
        // key pattern `.{ key: value }`
        consume(TOKEN.IDENTIFIER, "Expect key for hashmap.")
        let key = parser.previous.lexeme
        emitConstant(ObjectString(key), parser.previous.line)
      }

      consume(TOKEN.COLON, "Expect ':' for hashmap.")
      let assocLine = parser.previous.line

      // value
      expression()

      // associate key vlaue to hashmap
      emitByte(OP.ASSOC, assocLine)
    }

    if hasNextKeyValuePair() {
      keyvalue()

      for match(TOKEN.COMMA) and hasNextKeyValuePair() {
        keyvalue()
      }
    }

    consume(TOKEN.RIGHT_BRACE, "Expect '}' after hashmap.")
  }

  fn array() {
    emitByte(OP.ARRAY, parser.previous.line)

    fn hasNextValue() {
      !check(TOKEN.RIGHT_BRACKET) and !check(TOKEN.EOF)
    }
    if hasNextValue() {
      expression()
      emitByte(OP.APPEND, parser.previous.line)

      for match(TOKEN.COMMA) and hasNextValue() {
        expression()
        emitByte(OP.APPEND, parser.previous.line)
      }
    }
    consume(TOKEN.RIGHT_BRACKET, "Expect ']' after array.")
  }

  fn number() {
    let value = parser.previous.literal
    let line = parser.previous.line
    if value >= 0 and value < 256 and int(value) == value {
      emitBytes(OP.CONST_BYTE, value, line)
    } else {
      emitConstant(NUMBER_VAL(value), line)
    }
  }

  fn or_() {
    emitByte(OP.DUP, parser.previous.line)
    let endJump = emitJump(OP.JUMP_IF_TRUE)
    emitByte(OP.POP, parser.previous.line)
    parsePrecedence(PREC.OR)
    patchJump(endJump)
  }

  fn patchBreaks() {
    let chunk = currentChunk()
    let breaker = breakOffsets[len(breakOffsets) - 1]
    let currentAddr = len(currentChunk().bytecode)
    each(breaker, fn(addr) {
      let jump = currentAddr - addr - 2

      if jump > UINT16_MAX {
        error("Too much code to jump over.")
      }
      let upper = lib.tohex(int(jump / 256))
      let lower = lib.tohex(jump % 256)

      chunk.bytecode[addr] = upper
      chunk.bytecode[addr + 1] = lower
    })
  }

  fn patchContinues() {
    let chunk = currentChunk()
    let continues = continueOffsets[len(continueOffsets) - 1]
    let currentAddr = len(currentChunk().bytecode)
    each(continues, fn(addr) {
      let jump = currentAddr - addr - 2

      if jump > UINT16_MAX {
        error("Loop body too large.")
      }
      let upper = lib.tohex(int(jump / 256))
      let lower = lib.tohex(jump % 256)

      chunk.bytecode[addr] = upper
      chunk.bytecode[addr + 1] = lower
    })
  }

  fn forExpr() {
    beginScope()

    let result = reserveLocal()

    let prevScopeDepth = loopScopeDepth
    loopScopeDepth = current.scopeDepth

    push(breakOffsets, [])
    push(continueOffsets, [])

    let loopStart = len(currentChunk().bytecode)
    let loopStartLine = parser.previous.line

    let exitJump = -1

    fn forCond() {
      // helper to parse after `for init;` part,
      // we start to parse for optional `cond` part
      if !match(TOKEN.SEMICOLON) {
        // has cond part
        expression()
        exitJump = emitJump(OP.JUMP_IF_FALSE)
        consume(TOKEN.SEMICOLON, "Expect ';' after loop condition.")
      }

      // start to parse iter part
      if !check(TOKEN.LEFT_BRACE) {
        // has iter part
        let bodyJump = emitJump(OP.JUMP)
        let incrementStart = len(currentChunk().bytecode)
        expression()
        emitByte(OP.POP, parser.previous.line)
        emitLoop(loopStart, parser.previous.line)
        loopStart = incrementStart
        patchJump(bodyJump)
      }
    }

    if match(TOKEN.SEMICOLON) {
      // is a `for;;` without initializer
      // condition expression
      forCond()
    } else {
      // could be a `for cond {}` or `for init;;{}`
      // we want to point loopStart right before cond only
      expression()
      if !match(TOKEN.SEMICOLON) {
        // is `for cond {}` while loop
        // so above expression is treated as term cond
        // we don't need to update loopStart
        exitJump = emitJump(OP.JUMP_IF_FALSE)
      } else {
        // is `for init;cond; {}`, update loopStart
        // pop off init expression value
        emitByte(OP.POP, parser.previous.line)
        loopStart = len(currentChunk().bytecode)
        loopStartLine = parser.previous.line

        forCond()
      }
    }

    consume(TOKEN.LEFT_BRACE, "Expect '{' for block.")
    blocker()
    emitBytes(OP.SET_LOCAL, result, parser.previous.line)
    emitByte(OP.POP, parser.previous.line)

    patchContinues()

    emitLoop(loopStart, loopStartLine)

    if exitJump != -1 {
      patchJump(exitJump)
    }

    endScope()
    // break jump to where after loop cleanup
    // since we want to let break do their own POPN
    patchBreaks()

    loopScopeDepth = prevScopeDepth
    pop(breakOffsets)
    pop(continueOffsets)

    emitBytes(OP.GET_LOCAL, result, parser.previous.line)
  }

  fn breakExpr() {
    if len(breakOffsets) == 0 {
      error("Can only break inside a loop.")
      return
    }
    fn appendBreakOffsets() {
      resetScopeVariables(loopScopeDepth - 1)
      let breaker = breakOffsets[len(breakOffsets) - 1]
      let jump = emitJump(OP.JUMP)
      breakOffsets[len(breakOffsets) - 1] = append(breaker, jump)
    }
    if check(TOKEN.RIGHT_BRACE) {
      appendBreakOffsets()
      return
    }
    // optionally break with value
    expression()
    // make sure break is the last statement in current block
    if !check(TOKEN.RIGHT_BRACE) {
      error("Can only break at end of block.")
    }
    emitBytes(OP.SET_LOCAL, 1, parser.previous.line)
    // we reserved slot 1   ^ to store loop result
    appendBreakOffsets()

  }

  fn continueExpr() {
    if len(continueOffsets) == 0 {
      error("Can only continue inside a loop.")
      return
    }
    resetScopeVariables(loopScopeDepth)
    let continues = continueOffsets[len(continueOffsets) - 1]
    let jump = emitJump(OP.JUMP)
    continueOffsets[len(continueOffsets) - 1] = append(continues, jump)
  }

  fn string() {
    let line = parser.previous.line
    emitConstant(ObjectString(parser.previous.literal), line)
  }

  fn namedVariable(name, canAssign) {
    let line = parser.previous.line

    let getOp
    let setOp
    let arg = resolveLocal(current, name)

    if arg != -1 {
      getOp = OP.GET_LOCAL
      setOp = OP.SET_LOCAL
    } else if (arg = resolveUpvalue(current, name)) != -1 {
      getOp = OP.GET_UPVALUE
      setOp = OP.SET_UPVALUE
    } else {
      arg = identifierConstant(name)
      getOp = OP.GET_GLOBAL
      setOp = OP.SET_GLOBAL
    }

    if canAssign and match(TOKEN.EQUAL) {
      expression()
      emitBytes(setOp, arg, line)
    } else {
      emitBytes(getOp, arg, line)
    }
  }

  fn variable(canAssign) {
    namedVariable(parser.previous.lexeme, canAssign)
  }

  fn unary() {
    let opType = parser.previous.type
    let line = parser.previous.line

    parsePrecedence(PREC.UNARY)

    let opCodes = .{
      [TOKEN.BANG]: OP.NOT,
      [TOKEN.MINUS]: OP.NEGATE,
    }
    let opCode = opCodes[opType]
    if opCode {
      emitByte(opCode, line)
    } else {
      // unreachable, supposely
      error("bad unary op: " + types.TOKEN_NAME[opType])
    }
  }

  parseRules = .{
    [TOKEN.IMPORT]         : [nil,             nil,    PREC.NONE],
    [TOKEN.LEFT_PAREN]     : [grouping,        call,   PREC.CALL],
    [TOKEN.RIGHT_PAREN]    : [nil,             nil,    PREC.NONE],
    [TOKEN.LEFT_BRACE]     : [blocker,         nil,    PREC.NONE],
    [TOKEN.RIGHT_BRACE]    : [nil,             nil,    PREC.NONE],
    [TOKEN.LEFT_BRACKET]   : [array,           index,  PREC.CALL],
    [TOKEN.RIGHT_BRACKET]  : [nil,             nil,    PREC.NONE],
    [TOKEN.DOT_BRACE]      : [hashmap,         nil,    PREC.NONE],
    [TOKEN.COMMA]          : [nil,             nil,    PREC.NONE],
    [TOKEN.DOT]            : [nil,             dot,    PREC.CALL],
    [TOKEN.MINUS]          : [unary,           binary, PREC.TERM],
    [TOKEN.MINUS_GREATER]  : [nil,             arrow,  PREC.CALL],
    [TOKEN.PLUS]           : [nil,             binary, PREC.TERM],
    [TOKEN.SEMICOLON]      : [nil,             nil,    PREC.NONE],
    [TOKEN.SLASH]          : [nil,             binary, PREC.FACTOR],
    [TOKEN.STAR]           : [nil,             binary, PREC.FACTOR],
    [TOKEN.MOD]            : [nil,             binary, PREC.FACTOR],
    [TOKEN.BANG]           : [unary,           nil,    PREC.NONE],
    [TOKEN.BANG_EQUAL]     : [nil,             binary, PREC.EQUALITY],
    [TOKEN.EQUAL]          : [nil,             nil,    PREC.NONE],
    [TOKEN.EQUAL_EQUAL]    : [nil,             binary, PREC.EQUALITY],
    [TOKEN.GREATER]        : [nil,             binary, PREC.COMPARISON],
    [TOKEN.GREATER_EQUAL]  : [nil,             binary, PREC.COMPARISON],
    [TOKEN.GREATER_GREATER]: [nil,             binary, PREC.BIT_SHIFT],
    [TOKEN.LESS]           : [nil,             binary, PREC.COMPARISON],
    [TOKEN.LESS_EQUAL]     : [nil,             binary, PREC.COMPARISON],
    [TOKEN.LESS_LESS]      : [nil,             binary, PREC.BIT_SHIFT],
    [TOKEN.AMPERSAND]      : [nil,             binary, PREC.BIT_AND],
    [TOKEN.PIPE]           : [nil,             binary, PREC.BIT_OR],
    [TOKEN.CARET]          : [nil,             binary, PREC.BIT_XOR],
    [TOKEN.LET]            : [letExpr,         nil,    PREC.NONE],
    [TOKEN.IDENTIFIER]     : [variable,        nil,    PREC.NONE],
    [TOKEN.STRING]         : [string,          nil,    PREC.NONE],
    [TOKEN.NUMBER]         : [number,          nil,    PREC.NONE],
    [TOKEN.AND]            : [nil,             and_,   PREC.AND],
    [TOKEN.ELSE]           : [nil,             nil,    PREC.NONE],
    [TOKEN.FALSE]          : [literal,         nil,    PREC.NONE],
    [TOKEN.FOR]            : [forExpr,         nil,    PREC.NONE],
    [TOKEN.FN]             : [fnExpr,          nil,    PREC.NONE],
    [TOKEN.IF]             : [ifExpr,          nil,    PREC.NONE],
    [TOKEN.NIL]            : [literal,         nil,    PREC.NONE],
    [TOKEN.OR]             : [nil,             or_,    PREC.OR],
    [TOKEN.RETURN]         : [returnStatement, nil,    PREC.NONE],
    [TOKEN.BREAK]          : [breakExpr,       nil,    PREC.NONE],
    [TOKEN.CONTINUE]       : [continueExpr,    nil,    PREC.NONE],
    [TOKEN.TRUE]           : [literal,         nil,    PREC.NONE],
    [TOKEN.ERROR]          : [nil,             nil,    PREC.NONE],
    [TOKEN.EOF]            : [nil,             nil,    PREC.NONE],
  }

  getRule = fn(type) {
    let rule = parseRules[type]
    return .{
      prefix: rule[0],
      infix: rule[1],
      precedence: rule[2],
    }
  }

  isModule and beginScope()

  advance()
  for !match(TOKEN.EOF) {
    expressionStatement()
  }
  consume(TOKEN.EOF, "Expect end of expression.")
  let func = endCompiler()

  // XXX: warn on unused (global) variables

  return .{
    success: !parser.hadError,
    function: purifyFunction(func),
  }
}

