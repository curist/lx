# Parser Phase (`src/passes/frontend/parser.lx`)

## Responsibility

Convert source text into an AST with stable node IDs and accurate source ranges.

**Input**: Source string, filename
**Output**: AST + syntax errors only

## API

```lx
fn parse(src, filename) → {
  success: bool,
  ast: ProgramNode,
  errors: [string],        // Syntax errors (strings)
  nextNodeId: number,      // For later phases to continue allocating IDs
}
```

## Usage

```lx
let parse = import "src/passes/frontend/parser.lx"
let result = parse(sourceCode, filename)
```

## Syntax Model

The parser is expression-oriented: it returns a root `Block` node (no braces) whose `expressions` are the file’s top-level expressions (including “statement-like” forms).

Supported forms include:
- Literals: number, string, `true`/`false`, `nil`
- Identifiers
- Grouping: `(expr)`
- Unary: `!expr`, `-expr`
- Binary: `+ - * / %`, bitwise `| ^ &`, shifts `<< >>`, comparisons, equality
- Logical: `and`, `or`
- Calls: `callee(args...)`
- Index: `obj[expr]`
- Dot: `obj.key` (property is a `String` node)
- Arrays: `[a, b, ...]`
- Hashmaps: `.{ key: value, [expr]: value, ... }`
- Pipeline operator: `left->right` (produces an `Arrow` node)
- Block: `{ expr... }`
- `let name` / `let name = expr`
- `fn name?(params...) { body }`
- `if cond { then } else { else }` (including `else if ...`)
- `for cond { body }` and C-style `for init?; cond?; update? { body }`
- `return expr?`, `break expr?`, `continue`
- `import "path.lx"` (parsed as an `Import` node; statement-like)

Statement separators:
- Semicolons are optional; the parser skips extra `;` at the top level and inside blocks.
- Newlines/whitespace can separate expressions when the next token can’t continue the previous expression (see `test/parser.test.lx` for examples).

## Operator Precedence & Associativity

From low → high (see `PREC` in `src/passes/frontend/parser.lx`):
1. Assignment: `=` (only valid for identifiers, dot, and index targets)
2. `or`
3. `and`
4. Bitwise: `|`, `^`, `&`
5. Equality: `==`, `!=`
6. Comparison: `<`, `>`, `<=`, `>=`
7. Pipeline: `->`
8. Shifts: `<<`, `>>`
9. Term: `+`, `-`
10. Factor: `*`, `/`, `%`
11. Unary: `!`, unary `-`
12. Call/index/dot: `()`, `[]`, `.`

Associativity notes:
- Binary/logical operators are left-associative.
- Pipeline `->` is left-associative: `a->f()->g()` parses as `(a->f())->g()`.

## AST Node Model

### Base Fields

Every node has:

```lx
{
  id: number,          // Unique within a single parse() call
  type: string,
  filename: string,
  line: number,
  col: number,
  endLine: number,
  endCol: number,
  // ... node-specific fields
}
```

Node IDs:
- `nodeIdCounter` resets to 0 at the start of `parse()`.
- IDs increment as nodes are constructed; `parse()` returns `nextNodeId: nodeIdCounter + 1`.

Source ranges:
- The scanner’s `token.col` points after the token; most leaf nodes compute `col = token.col - len(token.lexeme)` and `endCol = token.col`.
- Composite nodes typically span from the left-most child (`col`) to the right-most child or closing delimiter (`endCol`).

### Node Shapes (selected)

- Root `Block`: `{ expressions: [Expr] }`
- Literals: `Number { value, lexeme }`, `String { value, lexeme }`, `Bool { value, lexeme }`, `Nil { lexeme }`
- `Identifier`: `{ name, lexeme }`
- `Grouping`: `{ expression }`
- `Unary`: `{ operator: {type, lexeme, line, col}, operand }`
- `Binary`/`Logical`: `{ left, operator: {type, lexeme, line, col}, right }`
- `Assignment`: `{ target, value }` where `target` is `Identifier` | `Dot` | `Index`
- `Array`: `{ elements: [Expr] }`
- `Hashmap`: `{ pairs: [{ key, value }] }` where `key` is either a `String` node (for bare keys) or an expression node (for `[expr]` keys)
- `Call`: `{ callee, args: [Expr] }`
- `Index`: `{ object, index }`
- `Dot`: `{ object, property }` where `property` is a `String` node
- `Arrow`: `{ left, operator: {type, lexeme, line, col}, right }`
- `Block`: `{ expressions: [Expr] }`
- `Let`: `{ name: Identifier, init: Expr? }`
- `Function`: `{ name: Identifier?, params: [Identifier], body: Block }`
- `If`: `{ condition, then: Block, else: Block | If | nil }`
- `For`: `{ init: Expr?, condition: Expr?, update: Expr?, body: Block }`
- `Return`: `{ value: Expr? }`
- `Break`: `{ value: Expr? }`
- `Continue`: `{}` (no extra fields)
- `Import`: `{ path: String }`

Key detail: dot/hashmap “bare keys” (including keywords like `if`, `return`, `true`, `nil`) are normalized to `String` nodes via `StringKeyNodeFromToken()`.

## Validation & Errors

The parser does syntax validation only. Semantic checks live in later phases (e.g. “return not at end”, “break outside loop”, name resolution).

Error behavior:
- `errors` is an array of strings generated by `errorAt()`.
- The parser uses panic-mode recovery and `synchronize()` to continue parsing after an error and collect multiple messages.

## Testing

- Parser tests: `./out/lx run lx/test/parser.test.lx`
- All tests: `make test`
